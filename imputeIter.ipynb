{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e603dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Danceability', 'Energy', 'Key', 'Loudness', 'Speechiness',\n",
      "       'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo',\n",
      "       'Duration_ms', 'Views', 'Likes', 'Stream', 'Composer', 'Artist',\n",
      "       'Licensed', 'official_video', 'Album_type'],\n",
      "      dtype='object')\n",
      "       Danceability    Energy  Key   Loudness  Speechiness  Acousticness  \\\n",
      "0               0.0  0.000273  3.0 -25.176000       0.0443  7.241508e-01   \n",
      "1               0.0  0.184220  7.0 -12.390073          NaN  6.722214e-01   \n",
      "2               0.0  0.054337  6.0 -15.596000          NaN  6.676276e-01   \n",
      "3               1.0  0.209585  NaN  -6.251000       0.0277  3.796416e-03   \n",
      "4               4.0       NaN  5.0  -6.219846       0.0260  3.048625e-06   \n",
      "...             ...       ...  ...        ...          ...           ...   \n",
      "17165           3.0  0.794023  5.0  -6.344000       0.0328  8.991539e-02   \n",
      "17166           2.0  0.820026  4.0  -1.786000          NaN  2.195200e-05   \n",
      "17167           1.0  0.571787  4.0  -4.679000       0.0647  2.379342e-02   \n",
      "17168           1.0  0.451218  9.0  -6.724091       0.4190  4.511802e-02   \n",
      "17169           2.0  0.825294  6.0  -4.543000       0.1070  2.125393e-08   \n",
      "\n",
      "       Instrumentalness  Liveness  Valence    Tempo  Duration_ms  \\\n",
      "0              0.000062  0.000807   0.3400   83.398     117907.0   \n",
      "1              0.910000  0.034966   0.7460  148.692     173427.0   \n",
      "2              0.867000  0.001772   0.3800   84.899     150667.0   \n",
      "3                   NaN  0.001000      NaN  150.220     265000.0   \n",
      "4              0.000467  0.002924   0.2950   97.997     263867.0   \n",
      "...                 ...       ...      ...      ...          ...   \n",
      "17165          0.000000  0.000591   0.6580   90.002      94667.0   \n",
      "17166          0.000000  0.000786   0.6570  174.869     150857.0   \n",
      "17167          0.000000  0.003652   0.4190  168.388     136842.0   \n",
      "17168               NaN  0.001260   0.5390  155.378     108387.0   \n",
      "17169          0.911000  0.002515   0.0787  160.067     181500.0   \n",
      "\n",
      "              Views         Likes       Stream  Composer  Artist  Licensed  \\\n",
      "0      7.367122e+07  1.376220e+05   19981370.0         6    34.0         0   \n",
      "1      1.848250e+05  5.190000e+03          NaN        10    32.0         0   \n",
      "2      1.848250e+05  5.190000e+03   19320810.0        10    13.0         0   \n",
      "3      2.024573e+08  9.970350e+05  399661898.0         5    86.0         1   \n",
      "4      3.166880e+08  1.299086e+06          NaN         8    74.0         1   \n",
      "...             ...           ...          ...       ...     ...       ...   \n",
      "17165  7.366938e+07  1.113000e+03          NaN        10    35.0         1   \n",
      "17166  1.647410e+05  2.019000e+03   10898176.0         8    27.0         1   \n",
      "17167  3.564600e+04  3.290000e+02          NaN         3     NaN         1   \n",
      "17168  6.533000e+03  5.548506e+05    6873961.0        10    55.0         1   \n",
      "17169  1.586970e+05  2.484000e+03    5695584.0         8    48.0         1   \n",
      "\n",
      "       official_video  Album_type  \n",
      "0                   0         2.0  \n",
      "1                   0         NaN  \n",
      "2                   0         NaN  \n",
      "3                   0         2.0  \n",
      "4                   1         2.0  \n",
      "...               ...         ...  \n",
      "17165               1         NaN  \n",
      "17166               0         1.0  \n",
      "17167               1         1.0  \n",
      "17168               1         1.0  \n",
      "17169               1         1.0  \n",
      "\n",
      "[17170 rows x 19 columns]\n",
      "        Energy   Key   Loudness  Speechiness  Acousticness  Instrumentalness  \\\n",
      "0     0.350403   6.0  -6.679000     0.177000  5.842771e-07          0.002330   \n",
      "1     0.347429   8.0  -5.815000     0.030200  9.846457e-02          0.000687   \n",
      "2     0.786330   1.0  -3.930000     0.052200  7.676563e-05               NaN   \n",
      "3     0.403583   2.0  -5.810000     0.026000  3.442951e-15          0.509000   \n",
      "4     0.334255   NaN  -8.627000     0.171000  1.619428e-05          0.000000   \n",
      "...        ...   ...        ...          ...           ...               ...   \n",
      "6310  0.160377   7.0  -6.366894     0.045451  3.176921e-01          0.006016   \n",
      "6311  0.318585  10.0  -4.148566     0.073000  7.419596e-03          0.000817   \n",
      "6312  0.426223   5.0  -5.807545     0.072906  6.617082e-01          0.898308   \n",
      "6313  0.204440   NaN -11.563964     0.037676  3.630868e-03          0.491785   \n",
      "6314  0.014679   NaN  -7.803241     0.082686  7.642603e-02          0.214188   \n",
      "\n",
      "      Liveness   Valence       Tempo    Duration_ms  ...  \\\n",
      "0     0.230346       NaN  138.559000  222640.000000  ...   \n",
      "1     0.000099  0.852000   92.761000  200173.000000  ...   \n",
      "2     0.001561  0.551000  108.014000  215150.000000  ...   \n",
      "3     0.000262  0.578000  120.423000  233867.000000  ...   \n",
      "4     0.000340  0.525000  167.953000  340920.000000  ...   \n",
      "...        ...       ...         ...            ...  ...   \n",
      "6310  0.001642  0.160253   72.136829  233721.956648  ...   \n",
      "6311  0.008843  0.614366         NaN  138726.388393  ...   \n",
      "6312  0.000662  0.087281   87.969239  185842.047750  ...   \n",
      "6313  0.030605  0.482987         NaN  180639.352865  ...   \n",
      "6314  0.001583  0.735073   98.873933  160431.173035  ...   \n",
      "\n",
      "                                              Album  \\\n",
      "0                                        Demon Days   \n",
      "1                                               NaN   \n",
      "2     New Gold (feat. Tame Impala and Bootie Brown)   \n",
      "3                                     Plastic Beach   \n",
      "4                                          Gorillaz   \n",
      "...                                             ...   \n",
      "6310               We're All Alone In This Together   \n",
      "6311                                        KISS 40   \n",
      "6312                                Young Right Now   \n",
      "6313                          Shawn Mendes (Deluxe)   \n",
      "6314                                            NaN   \n",
      "\n",
      "                                       Uri  \\\n",
      "0     spotify:track:0d28khcov6AiegSCpG5TuT   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      NaN   \n",
      "4                                      NaN   \n",
      "...                                    ...   \n",
      "6310  spotify:track:1MZqHpFyB4j5tFCFNvURou   \n",
      "6311  spotify:track:0roEMqT0P7Z82rJTwcID3Z   \n",
      "6312  spotify:track:6mz1fBdKATx6qP4oP1I65G   \n",
      "6313  spotify:track:4E6cwWJWZw2zWf7VFbH7wf   \n",
      "6314  spotify:track:5ln5yQdUywVbf8HhFsOcd6   \n",
      "\n",
      "                                            Url_spotify  \\\n",
      "0     https://open.spotify.com/artist/3AA28KZvwAUcZu...   \n",
      "1     https://open.spotify.com/artist/3AA28KZvwAUcZu...   \n",
      "2     https://open.spotify.com/artist/3AA28KZvwAUcZu...   \n",
      "3     https://open.spotify.com/artist/3AA28KZvwAUcZu...   \n",
      "4                                                   NaN   \n",
      "...                                                 ...   \n",
      "6310  https://open.spotify.com/artist/2QcZxAgcs2I1q7...   \n",
      "6311  https://open.spotify.com/artist/1WQBwwssN6r8DS...   \n",
      "6312  https://open.spotify.com/artist/4V8Sr092TqfHkf...   \n",
      "6313  https://open.spotify.com/artist/7eLcDZDYHXZCeb...   \n",
      "6314                                                NaN   \n",
      "\n",
      "                                      Url_youtube  Comments  \\\n",
      "0     https://www.youtube.com/watch?v=HyHNuVaZJ-k  169907.0   \n",
      "1     https://www.youtube.com/watch?v=yYDmaexVHic   31003.0   \n",
      "2     https://www.youtube.com/watch?v=qJa-VFwPpYA    7399.0   \n",
      "3                                             NaN   55229.0   \n",
      "4                                             NaN  155930.0   \n",
      "...                                           ...       ...   \n",
      "6310  https://www.youtube.com/watch?v=_JQiEs32SqQ     168.0   \n",
      "6311                                          NaN     448.0   \n",
      "6312  https://www.youtube.com/watch?v=ru3gH27Fn6E       NaN   \n",
      "6313  https://www.youtube.com/watch?v=0tGeMr5iXoA   15139.0   \n",
      "6314  https://www.youtube.com/watch?v=yxukv0gAhgY      11.0   \n",
      "\n",
      "                                            Description  \\\n",
      "0     Official HD Video for Gorillaz' fantastic trac...   \n",
      "1     The official video for Gorillaz - Rhinestone E...   \n",
      "2     Gorillaz - New Gold ft. Tame Impala & Bootie B...   \n",
      "3     Follow Gorillaz online:\\nhttp://gorillaz.com \\...   \n",
      "4     The official music video for Gorillaz - Clint ...   \n",
      "...                                                 ...   \n",
      "6310  MF DOOM & Madlib are Madvillain - Madvillainy ...   \n",
      "6311  Check out the brand-new album ‘When Was The La...   \n",
      "6312  Die Ärzte; offizielles Video zu \"Deine Schuld\"...   \n",
      "6313  Tiago PZK, Trueno - Salimo de Noche\\nSuscribit...   \n",
      "6314                                                NaN   \n",
      "\n",
      "                                                  Title           Channel  \\\n",
      "0            Gorillaz - Feel Good Inc. (Official Video)          Gorillaz   \n",
      "1     Gorillaz - Rhinestone Eyes [Storyboard Film] (...          Gorillaz   \n",
      "2     Gorillaz - New Gold ft. Tame Impala & Bootie B...          Gorillaz   \n",
      "3                                                   NaN          Gorillaz   \n",
      "4                                                   NaN          Gorillaz   \n",
      "...                                                 ...               ...   \n",
      "6310        The Mamas & The Papas - California Dreamin'    Eladio Carrion   \n",
      "6311  Kool Savas x Takt32 x Samra x GRiNGO - Check (...              RVFV   \n",
      "6312  Sleepy Hallow - Breaking Bad (Okay) ft. Sheff ...  Kappa Originals    \n",
      "6313      Tina Turner - The Best (Official Music Video)      CTanganaVEVO   \n",
      "6314       Nas - The World Is Yours (Official HD Video)   ChristmasTimeTV   \n",
      "\n",
      "     Composer Artist  \n",
      "0           8   44.0  \n",
      "1          10    NaN  \n",
      "2          10   89.0  \n",
      "3           4   27.0  \n",
      "4           5    NaN  \n",
      "...       ...    ...  \n",
      "6310        7    NaN  \n",
      "6311        2    NaN  \n",
      "6312        3   63.0  \n",
      "6313        2   32.0  \n",
      "6314        8   88.0  \n",
      "\n",
      "[6315 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23485, 18)\n"
     ]
    }
   ],
   "source": [
    "# imputer+ouo+no靖妤+(bert)\n",
    "# bert+pca(1??)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = pd.read_csv('ML_FP_train_v6.csv')\n",
    "print(data.columns)\n",
    "print(data)\n",
    "y = data['Danceability']\n",
    "# data['Composer'] = data['Composer'].fillna(0)\n",
    "# chart0c=data[['Composer','Danceability']]\n",
    "# chart0c=chart0c.groupby('Composer',as_index=False).mean().sort_values('Danceability',ascending=False)\n",
    "# chart0c['index'] = [float(i) for i in range(11)]\n",
    "# label_mapping = chart0c.set_index('Composer')['index'].to_dict()\n",
    "data = data[['Energy', 'Key', 'Loudness', 'Speechiness',\n",
    "       'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo',\n",
    "       'Duration_ms', 'Views', 'Likes', 'Stream', 'Album_type', 'Licensed',\n",
    "       'official_video', 'Composer', 'Artist']]\n",
    "\n",
    "\n",
    "# Encode labels in df1 to integers using the label_mapping dictionary\n",
    "#data['Composer'] = data['Composer'].map(label_mapping)\n",
    "\n",
    "sub_inf = pd.read_csv('ML_FP_test_v6.csv')\n",
    "print(sub_inf)\n",
    "tttest = sub_inf[['Energy', 'Key', 'Loudness', 'Speechiness',\n",
    "       'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo',\n",
    "       'Duration_ms', 'Views', 'Likes', 'Stream', 'Album_type', 'Licensed',\n",
    "       'official_video', 'Composer', 'Artist']]\n",
    "# tttest['Composer'] = tttest['Composer'].map(label_mapping)\n",
    "X = data.copy()\n",
    "sub_iid = pd.read_csv('ML_FP_test_v6.csv')\n",
    "sub_id  = sub_iid['id']\n",
    "merged = pd.concat([X, tttest], ignore_index=True)\n",
    "print(merged.shape)\n",
    "\n",
    "imputer = IterativeImputer(random_state=0) # 補植的方法\n",
    "\n",
    "# Fit and transform the data\n",
    "imputed_data = imputer.fit_transform(merged)\n",
    "\n",
    "# Convert the imputed data back to a dataframe\n",
    "imputed_ = pd.DataFrame(imputed_data, columns=data.columns)\n",
    "\n",
    "\n",
    "split_index = len(X)  # Index to split the DataFrame\n",
    "\n",
    "X_prebert = imputed_.iloc[:split_index]\n",
    "tttest_prebert = imputed_.iloc[split_index:]\n",
    "\n",
    "bb = pd.read_csv('bert_all.csv')\n",
    "imputed_df = pd.concat([imputed_, bb], axis=1)\n",
    "X = imputed_df.iloc[:split_index]\n",
    "tttest = imputed_df.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "44fd7553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17170, 18)\n",
      "(17170, 38)\n",
      "(6315, 18)\n",
      "(6315, 38)\n",
      "(17170,)\n"
     ]
    }
   ],
   "source": [
    "print(X_prebert.shape)\n",
    "print(X.shape)\n",
    "print(tttest_prebert.shape)\n",
    "print(tttest.shape)\n",
    "print(y.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "x_train_nb, x_test_nb, y_train, y_test = train_test_split(X_prebert, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3446e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rround(y_):\n",
    "    y_ = [round(num) for num in y_]\n",
    "    #y_ = [int(x) + 1 if x > int(x) + 0.7 else int(x) if x < int(x) + 0.3 else int(x) + 0.5 for x in y_]\n",
    "    y_ = [9 if x > 9 else x for x in y_]\n",
    "    y_ = [0 if x < 0 else x for x in y_]\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "085d9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t = pd.read_csv('test_partial_answer.csv')\n",
    "def test_acc(df1, df2):\n",
    "    merged_df = pd.merge(df1, df2, on='id', how='inner')\n",
    "\n",
    "    # Calculate accuracy (absolute difference)\n",
    "    merged_df['Accuracy'] = abs(merged_df['Danceability_x'] - merged_df['Danceability_y'])\n",
    "\n",
    "    # Calculate average accuracy\n",
    "    average_accuracy = merged_df['Accuracy'].mean()\n",
    "\n",
    "    #print(merged_df)\n",
    "    print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "269c0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 2.15689381933439\n"
     ]
    }
   ],
   "source": [
    "n_best = pd.read_csv('ols_sc_rb_submission.csv')\n",
    "test_acc(test_t, n_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b0c32e",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "acdedbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf = rf_model.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "#print(rf_model.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "40a4f02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13736\n",
      "Mean Squared Error: 4.210959784507863\n",
      "Mean Squared Error2: 4.299650553290623\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "y_pred = rf.predict(x_test)\n",
    "#print(rf_model.feature_names_in_)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "mse = mean_squared_error(y_test, rround(y_pred))\n",
    "print(\"Mean Squared Error2:\", mse)\n",
    "\n",
    "#no bert Mean Squared Error: 4.186648776936517\n",
    "# bert\n",
    "# Mean Squared Error: 4.235486051252184\n",
    "# Mean Squared Error2: 4.2778101339545715\n",
    "# pca bert\n",
    "# Mean Squared Error: 4.16308683750728\n",
    "# Mean Squared Error2: 4.216074548631334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9aa64dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17170\n",
      "6315\n",
      "[5.45 5.81 3.25 ... 3.79 4.22 4.81]\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(tttest))\n",
    "rf = rf_model.fit(X, y)\n",
    "\n",
    "y_submit = rf.predict(tttest)\n",
    "print(y_submit)\n",
    "#v1\n",
    "#Mean Squared Error: 4.38743715783343\n",
    "#[4.2  5.45 4.97 ... 3.87 4.43 5.08]\n",
    "y_ = y_submit.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30dfb100",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 2.1822503961965136\n",
      "         id  Danceability\n",
      "0     17170             5\n",
      "1     17171             6\n",
      "2     17172             3\n",
      "3     17173             5\n",
      "4     17174             6\n",
      "...     ...           ...\n",
      "6310  23480             2\n",
      "6311  23481             7\n",
      "6312  23482             4\n",
      "6313  23483             4\n",
      "6314  23484             5\n",
      "\n",
      "[6315 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_ = rround(y_)\n",
    "\n",
    "df = pd.DataFrame({'id': sub_id, 'Danceability': y_})\n",
    "test_acc(df, test_t)\n",
    "print(df)\n",
    "df.to_csv('output0511_0417.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97402a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.252183779848573\n",
      "Mean Squared Error2: 4.300815375655213\n",
      "[5.52 6.38 3.86 ... 3.59 4.15 3.99]\n",
      "Average Accuracy: 2.180316957210777\n"
     ]
    }
   ],
   "source": [
    "# no bert\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf = rf_model.fit(x_train_nb, y_train)\n",
    "y_pred = rf.predict(x_test_nb)\n",
    "#print(rf_model.feature_names_in_)\n",
    "\n",
    "#print(rf_model.feature_names_in_)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "mse = mean_squared_error(y_test, rround(y_pred))\n",
    "print(\"Mean Squared Error2:\", mse)\n",
    "\n",
    "rf = rf_model.fit(X_prebert, y)\n",
    "y_submit = rf.predict(tttest_prebert)\n",
    "print(y_submit)\n",
    "#v1\n",
    "#Mean Squared Error: 4.38743715783343\n",
    "#[4.2  5.45 4.97 ... 3.87 4.43 5.08]\n",
    "y_ = y_submit.tolist()\n",
    "df = pd.DataFrame({'id': sub_id, 'Danceability': y_})\n",
    "test_acc(df, test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25388d",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ff5f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7501456027955737\n",
      "3.661324162190281\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "xg5 = xgb.XGBRegressor(n_estimators= 1600, max_depth= 9, learning_rate= 0.01,colsample_bytree= 0.5)#(XGBRegressor(colsample_bytree= 0.6, learning_rate=0.03, max_depth= None, n_estimators=1200)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "xg5=xg5.fit(x_train, y_train)\n",
    "y_pred=xg5.predict(x_test)\n",
    "mse2 = mean_squared_error(y_test, y_pred)\n",
    "y_pred = rround(y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "print(mse2)\n",
    "# no bert\n",
    "# 3.9178800232964472\n",
    "# 3.8325537957190416\n",
    "# bert\n",
    "# 3.768782760629004\n",
    "# 3.6961818585097235\n",
    "# pca bert\n",
    "# 3.8692486895748397\n",
    "# 3.795434217386355\n",
    "# ouo+bert+imputer\n",
    "# 3.7009318578916717\n",
    "# 3.6424231889231544\n",
    "# ouo+bert+imputer+tune\n",
    "# 3.7009318578916717\n",
    "# 3.6334081875442323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1a21cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg5 = xgb.XGBRegressor(n_estimators= 1600, max_depth= 9, learning_rate= 0.01,colsample_bytree= 0.5)#((colsample_bytree= 0.6, learning_rate=0.03, max_depth= None, n_estimators=1200)\n",
    "xg5 = xg5.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7e5a1621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6315\n"
     ]
    }
   ],
   "source": [
    "print(len(tttest))\n",
    "y_submit = xg5.predict(tttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ce40310b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 2.1322850617336586\n",
      "         id  Danceability\n",
      "0     17170      5.559577\n",
      "1     17171      5.038537\n",
      "2     17172      4.107034\n",
      "3     17173      4.035712\n",
      "4     17174      5.152710\n",
      "...     ...           ...\n",
      "6310  23480      1.745009\n",
      "6311  23481      7.659138\n",
      "6312  23482      3.500906\n",
      "6313  23483      5.426163\n",
      "6314  23484      5.238286\n",
      "\n",
      "[6315 rows x 2 columns]\n",
      "         id  Danceability\n",
      "0     17170             6\n",
      "1     17171             5\n",
      "2     17172             4\n",
      "3     17173             4\n",
      "4     17174             5\n",
      "...     ...           ...\n",
      "6310  23480             2\n",
      "6311  23481             8\n",
      "6312  23482             4\n",
      "6313  23483             5\n",
      "6314  23484             5\n",
      "\n",
      "[6315 rows x 2 columns]\n",
      "Average Accuracy: 2.115689381933439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_ = y_submit.tolist()\n",
    "\n",
    "df = pd.DataFrame({'id': sub_id, 'Danceability': y_})\n",
    "test_acc(df, test_t)\n",
    "print(df)\n",
    "df.to_csv('output0511_0418.csv', index=False)\n",
    "\n",
    "y_ = rround(y_)\n",
    "\n",
    "df = pd.DataFrame({'id': sub_id, 'Danceability': y_})\n",
    "print(df)\n",
    "df.to_csv('output0511_0419.csv', index=False)\n",
    "test_acc(df, test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d68c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8296447291788\n",
      "3.753448690368451\n"
     ]
    }
   ],
   "source": [
    "#no_bert\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xg5 = xgb.XGBRegressor(n_estimators= 1600, max_depth= 9, learning_rate= 0.01,colsample_bytree= 0.5)#((colsample_bytree= 0.6, learning_rate=0.03, max_depth= None, n_estimators=1200)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "xg5=xg5.fit(x_train_nb, y_train)\n",
    "y_pred=xg5.predict(x_test_nb)\n",
    "mse2 = mean_squared_error(y_test, y_pred)\n",
    "y_pred = rround(y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "print(mse2)\n",
    "#no bert3.9178800232964472\n",
    "#3.8325537957190416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df6ff402",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg5 = xgb.XGBRegressor(n_estimators= 1600, max_depth= 9, learning_rate= 0.01,colsample_bytree= 0.5)#(colsample_bytree= 0.6, learning_rate=0.03, max_depth= None, n_estimators=1200)\n",
    "xg5 = xg5.fit(X_prebert, y)\n",
    "y_submit = xg5.predict(tttest_prebert)\n",
    "\n",
    "y_ = y_submit.tolist()\n",
    "df = pd.DataFrame({'id': sub_id, 'Danceability': y_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1777c4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 2.1282848111234265\n",
      "         id  Danceability\n",
      "0     17170      5.212711\n",
      "1     17171      5.324709\n",
      "2     17172      4.113466\n",
      "3     17173      3.561276\n",
      "4     17174      5.447711\n",
      "...     ...           ...\n",
      "6310  23480      1.637880\n",
      "6311  23481      7.554855\n",
      "6312  23482      3.323893\n",
      "6313  23483      5.330450\n",
      "6314  23484      5.163568\n",
      "\n",
      "[6315 rows x 2 columns]\n",
      "         id  Danceability\n",
      "0     17170             5\n",
      "1     17171             5\n",
      "2     17172             4\n",
      "3     17173             4\n",
      "4     17174             5\n",
      "...     ...           ...\n",
      "6310  23480             2\n",
      "6311  23481             8\n",
      "6312  23482             3\n",
      "6313  23483             5\n",
      "6314  23484             5\n",
      "\n",
      "[6315 rows x 2 columns]\n",
      "Average Accuracy: 2.1378763866877972\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('output0511_0420.csv', index=False)\n",
    "test_acc(df, test_t)\n",
    "print(df)\n",
    "y_ = rround(y_)\n",
    "\n",
    "df = pd.DataFrame({'id': sub_id, 'Danceability': y_})\n",
    "print(df)\n",
    "df.to_csv('output0511_0421.csv', index=False)\n",
    "test_acc(df, test_t)\n",
    "# Average Accuracy: 2.121677498981097\n",
    "# Average Accuracy: 2.114104595879556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9db3afaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, None],\n",
       " 'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.09, 0.12, 0.14, 0.16, 0.18, 0.2],\n",
       " 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 大tune特tune\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_depth = [int(x) for x in np.linspace(1, 11, num=11)]\n",
    "max_depth.append(None)\n",
    "learning_rate=[round(float(x),2) for x in np.linspace(start=0.01, stop=0.2, num=10)]\n",
    "colsample_bytree =[round(float(x),2) for x in np.linspace(start=0.1, stop=1, num=10)]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'learning_rate': learning_rate,\n",
    "               'colsample_bytree': colsample_bytree}\n",
    "random_grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad0ba8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Random search of parameters, using 3 fold cross validation, search across 100 different combinations, and use all available cores\u001b[39;00m\n\u001b[0;32m      4\u001b[0m xg_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator \u001b[38;5;241m=\u001b[39m xg4, param_distributions\u001b[38;5;241m=\u001b[39mrandom_grid,\n\u001b[0;32m      5\u001b[0m                               n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mxg_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_nb\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m xg_random\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xg4 = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "#Random search of parameters, using 3 fold cross validation, search across 100 different combinations, and use all available cores\n",
    "xg_random = RandomizedSearchCV(estimator = xg4, param_distributions=random_grid,\n",
    "                              n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "xg_random.fit(x_train_nb,y_train)\n",
    "xg_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c015cf3",
   "metadata": {},
   "source": [
    "# pca bert cell_1->this->cell_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e9c9c8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23485, 128)\n",
      "Transformed Data:\n",
      "[[ 0.74965274  4.91019383  0.01421809 ... -1.00853796 -0.54940566\n",
      "  -0.55335962]\n",
      " [ 2.17563501  1.80990828 -1.06249165 ... -0.67291899 -1.46211201\n",
      "  -0.19950925]\n",
      " [ 2.17563501  1.80990828 -1.06249165 ... -0.67291899 -1.46211201\n",
      "  -0.19950925]\n",
      " ...\n",
      " [-1.43822298  4.7593385  -2.19635838 ... -0.60114172 -0.40384402\n",
      "  -1.60416858]\n",
      " [-3.0855156  -2.08006222 -3.27427677 ... -0.41621601  0.0837697\n",
      "  -0.13250717]\n",
      " [ 8.64635101 -1.26154942 -0.29134027 ... -0.08465516 -0.03545006\n",
      "   0.10121821]]\n",
      "(23485, 20)\n",
      "Principal Components:\n",
      "[[-7.41173800e-02  1.15611832e-01 -4.32474879e-02 ... -5.31673806e-02\n",
      "   7.29493311e-02 -1.47207944e-01]\n",
      " [-3.06940178e-02 -9.64543776e-02 -1.76173898e-01 ...  5.53533181e-03\n",
      "   2.99629477e-02  2.41818511e-01]\n",
      " [ 3.34576357e-02  1.90813964e-02 -6.19551199e-02 ...  8.31613063e-02\n",
      "   1.01425975e-01  5.17694625e-02]\n",
      " ...\n",
      " [ 3.85869471e-02 -1.41067425e-02  1.00002278e-01 ...  9.15998102e-02\n",
      "   3.53387999e-02  6.27252477e-02]\n",
      " [ 1.27127917e-04  1.37212627e-01  8.26153523e-02 ... -4.06520711e-02\n",
      "   6.54137144e-03  2.76894735e-02]\n",
      " [ 1.92176398e-02 -4.62474772e-02  9.00066869e-02 ... -8.87394057e-02\n",
      "  -6.91371524e-02  6.84789578e-03]]\n",
      "Explained Variance Ratio:\n",
      "[0.28565911 0.1184958  0.11205704 0.07322638 0.04282296 0.02601271\n",
      " 0.02351415 0.01980958 0.01651451 0.01523401 0.01324132 0.01144724\n",
      " 0.01093673 0.01033158 0.00905332 0.00859546 0.00835526 0.00809701\n",
      " 0.00794277 0.00712909]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming arr is your NumPy array\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Create a PCA \n",
    "nofpca = 20\n",
    "pca = PCA(n_components=nofpca)\n",
    "xx = bb.values\n",
    "print(xx.shape)\n",
    "# Fit the PCA model to the data\n",
    "pca.fit(xx)\n",
    "\n",
    "# Transform the data using the PCA model\n",
    "transformed_data = pca.transform(xx)\n",
    "\n",
    "# Access the principal components\n",
    "principal_components = pca.components_\n",
    "\n",
    "# Access the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed data\n",
    "print(\"Transformed Data:\")\n",
    "print(transformed_data)\n",
    "print(transformed_data.shape)\n",
    "\n",
    "transformed_data = pd.DataFrame(transformed_data, columns=[str(i) for i in range(nofpca)])\n",
    "imputed_df = pd.concat([imputed_, transformed_data], axis=1)\n",
    "X = imputed_df.iloc[:split_index]\n",
    "tttest = imputed_df.iloc[split_index:]\n",
    "# Print the principal components\n",
    "print(\"Principal Components:\")\n",
    "print(principal_components)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d875f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('train_ouo_bert_pca3.csv', index=False)\n",
    "tttest.to_csv('test_ouo_bert_pca3.csv',index=False)\n",
    "X_prebert.to_csv('train_ouo_imputer.csv', index=False)\n",
    "tttest_prebert.to_csv('test_ouo_imputer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4274e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23485, 128)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
