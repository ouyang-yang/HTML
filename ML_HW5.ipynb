{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm.svmutil import *\n",
    "from liblinear.liblinearutil import *\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = svm_read_problem(\"letter_train\")\n",
    "y_test, X_test = svm_read_problem(\"letter_test\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11~16: SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 99.2286% (10419/10500) (classification)\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# set \"a\" as positive, \"not a\" as negative, a=1\n",
    "a = 1\n",
    "y_train_1 = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == a:\n",
    "        y_train_1.append(1)\n",
    "    else:\n",
    "        y_train_1.append(-1)\n",
    "# linear kernel: -t=0\n",
    "param = f'-s 0 -t 0 -c 1 -q'\n",
    "model = svm_train(y_train_1, X_train , param)\n",
    "p_label, p_acc, p_val = svm_predict(y_train_1, X_train, model)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.309673609961578\n"
     ]
    }
   ],
   "source": [
    "# Obtain the coefficients and support vectors\n",
    "coef = model.get_sv_coef()\n",
    "SVs = model.get_SV()\n",
    "\n",
    "# Compute the weight vector 'w'\n",
    "w = np.zeros(len(X_train[0]))\n",
    "for i in range(len(coef)):\n",
    "    for j, x in SVs[i].items():\n",
    "        w[j-1] += coef[i][0] * x\n",
    "\n",
    "# Compute the norm of 'w'\n",
    "w_norm = np.linalg.norm(w)\n",
    "print(w_norm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.8667% (10381/10500) (classification)\n",
      "Accuracy = 99.3238% (10429/10500) (classification)\n",
      "Accuracy = 99.0381% (10399/10500) (classification)\n",
      "Accuracy = 98.5143% (10344/10500) (classification)\n",
      "Accuracy = 98.8762% (10382/10500) (classification)\n",
      "Ein for a=2: 0.011333333333333306, Number of support vectors: 588\n",
      "Ein for a=3: 0.006761904761904747, Number of support vectors: 368\n",
      "Ein for a=4: 0.009619047619047638, Number of support vectors: 499\n",
      "Ein for a=5: 0.014857142857142902, Number of support vectors: 642\n",
      "Ein for a=6: 0.01123809523809527, Number of support vectors: 503\n",
      "Max Ein: 0.014857142857142902\n",
      "a with Max Ein: 5\n",
      "Minimum number of support vectors: 368\n",
      "a with minimum number of support vectors: 3\n"
     ]
    }
   ],
   "source": [
    "y_train_lst = []\n",
    "a_lst = [2, 3, 4, 5, 6]\n",
    "Ein_lst = []\n",
    "models = []\n",
    "nsv_lst = [] # number of support vectors for each model\n",
    "\n",
    "for a in a_lst:\n",
    "    y_train_a = []\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] == a:\n",
    "            y_train_a.append(1)\n",
    "        else:\n",
    "            y_train_a.append(-1)\n",
    "\n",
    "    # polynomial kernel: -t=1\n",
    "    # degree=2: -d=2\n",
    "    param = f'-s 0 -t 1 -d 2 -r 1 -g 1 -c 1 -q'\n",
    "\n",
    "    model = svm_train(y_train_a, X_train, param)\n",
    "    models.append(model)  # append model to models list\n",
    "    p_label, p_acc, p_val = svm_predict(y_train_a, X_train, model)\n",
    "\n",
    "    Ein = 1-p_acc[0]/100\n",
    "    Ein_lst.append(Ein)\n",
    "\n",
    "    # get the number of support vectors for the trained model\n",
    "    nsv = model.get_nr_sv()\n",
    "    nsv_lst.append(nsv)\n",
    "\n",
    "for i, a in enumerate(a_lst):\n",
    "    print(f\"Ein for a={a}: {Ein_lst[i]}, Number of support vectors: {nsv_lst[i]}\")\n",
    "\n",
    "max_Ein_idx = np.argmax(Ein_lst)\n",
    "max_a = a_lst[max_Ein_idx]\n",
    "print(f\"Max Ein: {Ein_lst[max_Ein_idx]}\")\n",
    "print(f\"a with Max Ein: {max_a}\")\n",
    "\n",
    "min_nsv_idx = np.argmin(nsv_lst)\n",
    "min_a = a_lst[min_nsv_idx]\n",
    "print(f\"Minimum number of support vectors: {nsv_lst[min_nsv_idx]}\")\n",
    "print(f\"a with minimum number of support vectors: {min_a}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 95.48% (4774/5000) (classification)\n",
      "Accuracy = 95.48% (4774/5000) (classification)\n",
      "Accuracy = 98.58% (4929/5000) (classification)\n",
      "Accuracy = 99.6% (4980/5000) (classification)\n",
      "Accuracy = 99.46% (4973/5000) (classification)\n",
      "Values of C that result in the lowest Eout: [10]\n",
      "Smallest C value among those with the same lowest Eout: 10\n"
     ]
    }
   ],
   "source": [
    "# set \"a\" as positive, \"not a\" as negative, a=1\n",
    "a = 7\n",
    "y_train_7 = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == a:\n",
    "        y_train_7.append(1)\n",
    "    else:\n",
    "        y_train_7.append(-1)\n",
    "\n",
    "y7_test = []\n",
    "for j in range(len(y_test)):\n",
    "    if y_test[j] == a:\n",
    "        y7_test.append(1)\n",
    "    else:\n",
    "        y7_test.append(-1)\n",
    "\n",
    "C_lst = [0.01, 0.1, 1, 10, 100]\n",
    "Eout_lst = []\n",
    "\n",
    "for c in range(len(C_lst)):\n",
    "    # Gaussian kernel: -t=2\n",
    "    param = f'-s 0 -t 2 -g 1 -c {C_lst[c]} -q'\n",
    "    model = svm_train(y_train_7, X_train , param)\n",
    "    p_label, p_acc, p_val = svm_predict(y7_test, X_test, model)\n",
    "    Eout = 1 - p_acc[0] / 100\n",
    "    Eout_lst.append(Eout)\n",
    "\n",
    "min_Eout = min(Eout_lst)\n",
    "min_C_vals = [C_lst[i] for i in range(len(C_lst)) if Eout_lst[i] == min_Eout]\n",
    "min_C = min(min_C_vals)\n",
    "\n",
    "print(f\"Values of C that result in the lowest Eout: {min_C_vals}\")\n",
    "print(f\"Smallest C value among those with the same lowest Eout: {min_C}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15: C=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set \"a\" as positive, \"not a\" as negative, a=1\n",
    "a = 7\n",
    "y_train_7 = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == a:\n",
    "        y_train_7.append(1)\n",
    "    else:\n",
    "        y_train_7.append(-1)\n",
    "\n",
    "y7_test = []\n",
    "for j in range(len(y_test)):\n",
    "    if y_test[j] == a:\n",
    "        y7_test.append(1)\n",
    "    else:\n",
    "        y7_test.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 95.48% (4774/5000) (classification)\n",
      "Accuracy = 95.48% (4774/5000) (classification)\n",
      "Accuracy = 95.98% (4799/5000) (classification)\n",
      "Accuracy = 95.48% (4774/5000) (classification)\n",
      "Accuracy = 95.48% (4774/5000) (classification)\n",
      "Values of gamma that result in the lowest Eout: [10]\n",
      "Smallest gamma value among those with the same lowest Eout: 10\n"
     ]
    }
   ],
   "source": [
    "Eout_lst = []\n",
    "gammas = [0.1, 1, 10, 100, 1000]\n",
    "for g in range(len(gammas)):\n",
    "    # Gaussian kernel: -t=2\n",
    "    param = f'-s 0 -t 2 -g {gammas[g]} -c 0.1 -q'\n",
    "    model = svm_train(y_train_7, X_train , param)\n",
    "    p_label, p_acc, p_val = svm_predict(y7_test, X_test, model)\n",
    "    Eout = 1 - p_acc[0] / 100\n",
    "    Eout_lst.append(Eout)\n",
    "\n",
    "min_Eout = min(Eout_lst)\n",
    "min_gamma_vals = [gammas[i] for i in range(len(gammas)) if Eout_lst[i] == min_Eout]\n",
    "min_gamma = min(min_gamma_vals)\n",
    "\n",
    "print(f\"Values of gamma that result in the lowest Eout: {min_gamma_vals}\")\n",
    "print(f\"Smallest gamma value among those with the same lowest Eout: {min_gamma}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function print_null at 0x00000196FBD6C0D0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mayda\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\libsvm\\svm.py\", line 60, in print_null\n",
      "    def print_null(s):\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "num_iter = 500\n",
    "rng = np.random.default_rng()\n",
    "gammas = [0.1, 1, 10, 100, 1000]\n",
    "gamma_counts = {gamma: 0 for gamma in gammas}  # initialize the count for each gamma to 0\n",
    "iter_count = 0\n",
    "\n",
    "for t in range(num_iter):\n",
    "    indices = rng.choice(len(y_train_7), size=200, replace=False)\n",
    "    X_val = [X_train[i] for i in indices]\n",
    "    y_val = [y_train_7[i] for i in indices]\n",
    "    X_train_sub = [X_train[i] for i in range(len(X_train)) if i not in indices]\n",
    "    y_train_sub = [y_train_7[i] for i in range(len(y_train_7)) if i not in indices]\n",
    " \n",
    "    min_Eval = float('inf')\n",
    "    best_gamma = 0\n",
    "    for gamma in range(len(gammas)):\n",
    "        # train model on the training set\n",
    "        param = f'-s 0 -t 2 -g {gammas[gamma]} -c 0.1 -q'\n",
    "        model = svm_train(y_train_sub, X_train_sub, param)\n",
    "        p_label, p_acc, _ = svm_predict(y_val, X_val, model, '-q')\n",
    "        E_val = 1 - p_acc[0] / 100\n",
    "\n",
    "        # update the best gamma and minimum validation error if necessary\n",
    "        if E_val < min_Eval or (E_val == min_Eval and gamma < best_gamma):\n",
    "            best_gamma = gamma\n",
    "            min_Eval = E_val\n",
    "\n",
    "    # increment the count for the best gamma\n",
    "    gamma_counts[gammas[best_gamma]] += 1\n",
    "    iter_count +=1\n",
    "    print(iter_count, \" | \", \"Gamma counts:\", gamma_counts)\n",
    "\n",
    "# find the gamma with the maximum count\n",
    "max_gamma_count = max(gamma_counts.values())\n",
    "most_frequent_gammas = [gamma for gamma, count in gamma_counts.items() if count == max_gamma_count]\n",
    "\n",
    "print(\"Final gamma counts:\", gamma_counts)\n",
    "print(\"Most frequent gamma value(s):\", most_frequent_gammas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 試試能不能快一點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(gamma, X_train_sub, y_train_sub, X_val, y_val):\n",
    "    param = f'-s 0 -t 2 -g {gamma} -c 0.1 -q'\n",
    "    model = svm_train(y_train_sub, X_train_sub, param)\n",
    "    p_label, p_acc, _ = svm_predict(y_val, X_val, model, '-q')\n",
    "    E_val = 1 - p_acc[0] / 100\n",
    "    return gamma, E_val\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_iter = 500\n",
    "    rng = np.random.default_rng()\n",
    "    gammas = [0.1, 1, 10, 100, 1000]\n",
    "    manager = mp.Manager()\n",
    "    gamma_counts = manager.dict({gamma: 0 for gamma in gammas})  # initialize the count for each gamma to 0\n",
    "    iter_count = 0\n",
    "\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        for t in range(num_iter):\n",
    "            indices = rng.choice(len(y_train_7), size=200, replace=False)\n",
    "            X_val = [X_train[i] for i in indices]\n",
    "            y_val = [y_train_7[i] for i in indices]\n",
    "            X_train_sub = [X_train[i] for i in range(len(X_train)) if i not in indices]\n",
    "            y_train_sub = [y_train_7[i] for i in range(len(y_train_7)) if i not in indices]\n",
    "\n",
    "            results = pool.starmap(train_model, [(gamma, X_train_sub, y_train_sub, X_val, y_val) for gamma in gammas])\n",
    "            best_gamma, min_Eval = min(results, key=lambda x: x[1])\n",
    "\n",
    "            # increment the count for the best gamma\n",
    "            gamma_counts[best_gamma] += 1\n",
    "            iter_count +=1\n",
    "            print(iter_count, \" | \", \"Gamma counts:\", dict(gamma_counts))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    # find the gamma with the maximum count\n",
    "    max_gamma_count = max(gamma_counts.values())\n",
    "    most_frequent_gammas = [gamma for gamma, count in gamma_counts.items() if count == max_gamma_count]\n",
    "\n",
    "    print(\"Final gamma counts:\", dict(gamma_counts))\n",
    "    print(\"Most frequent gamma value(s):\", most_frequent_gammas)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17~20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500, 16)\n",
      "(10500,)\n",
      "(10500, 16)\n",
      "(10500,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "y_train, X_train = svm_read_problem(\"letter_train\")\n",
    "y_test, X_test = svm_read_problem(\"letter_test\")\n",
    "X_train = np.array([list(x.values()) for x in X_train])\n",
    "X_test = np.array([list(x.values()) for x in X_test])\n",
    "\n",
    "# Select binary classification problem: \"11\" versus \"26\"\n",
    "label1 = 11\n",
    "label2 = 26\n",
    "y_train_binary = np.where(np.array(y_train) == label1, 1, -1)\n",
    "y_test_binary = np.where(np.array(y_test) == label1, 1, -1)\n",
    "X_train_binary = X_train[(y_train_binary == 1) | (y_train_binary == -1)]\n",
    "y_train_binary = y_train_binary[(y_train_binary == 1) | (y_train_binary == -1)]\n",
    "X_test_binary = X_test[(y_test_binary == 1) | (y_test_binary == -1)]\n",
    "y_test_binary = y_test_binary[(y_test_binary == 1) | (y_test_binary == -1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate weighted error rate\n",
    "def calculate_weighted_error(y, y_pred, weights):\n",
    "    incorrect = (y != y_pred)\n",
    "    weighted_error = np.sum(weights[incorrect])\n",
    "    return weighted_error\n",
    "\n",
    "# Function to find the best threshold and polarity for a given feature\n",
    "def find_best_threshold(feature_values, y, weights):\n",
    "    thresholds = [-np.inf] + sorted(feature_values) + [np.inf]\n",
    "    best_polarity = 1\n",
    "    best_threshold = None\n",
    "    min_weighted_error = float('inf')\n",
    "\n",
    "    for i in range(len(thresholds) - 1):\n",
    "        midpoint = (thresholds[i] + thresholds[i + 1]) / 2\n",
    "\n",
    "        for polarity in [1, -1]:\n",
    "            y_pred = polarity * np.sign(feature_values - midpoint)\n",
    "            weighted_error = calculate_weighted_error(y, y_pred, weights)\n",
    "\n",
    "            if weighted_error < min_weighted_error:\n",
    "                min_weighted_error = weighted_error\n",
    "                best_polarity = polarity\n",
    "                best_threshold = midpoint\n",
    "\n",
    "    return best_polarity, best_threshold, min_weighted_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a decision stump (weak learner)\n",
    "def train_stump(X, y, weights):\n",
    "    num_features = X.shape[1]\n",
    "    best_polarity = None\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    min_weighted_error = float('inf')\n",
    "\n",
    "    for feature in range(num_features):\n",
    "        feature_values = X[:, feature]\n",
    "        polarity, threshold, weighted_error = find_best_threshold(feature_values, y, weights)\n",
    "\n",
    "        if weighted_error < min_weighted_error:\n",
    "            min_weighted_error = weighted_error\n",
    "            best_polarity = polarity\n",
    "            best_feature = feature\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_polarity, best_feature, best_threshold\n",
    "\n",
    "# Function to predict using a decision stump\n",
    "def predict_stump(X, polarity, feature, threshold):\n",
    "    return polarity * np.sign(X[:, feature] - threshold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adaboost Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform AdaBoost-Stump\n",
    "def adaboost_stump(X, y, T):\n",
    "    N = X.shape[0]\n",
    "    u = np.ones(N) / N  # Initialize weights uniformly\n",
    "\n",
    "    classifiers = []\n",
    "    alphas = []\n",
    "\n",
    "    for t in range(T):\n",
    "        # Train a decision stump\n",
    "        polarity, feature, threshold = train_stump(X, y, u)\n",
    "\n",
    "        # Calculate weighted error\n",
    "        y_pred = predict_stump(X, polarity, feature, threshold)\n",
    "        weighted_error = calculate_weighted_error(y, y_pred, u)\n",
    "\n",
    "        # Calculate alpha\n",
    "        alpha = 0.5 * np.log((1 - weighted_error) / weighted_error)\n",
    "\n",
    "        # Update weights\n",
    "        u *= np.exp(-alpha * y * y_pred)\n",
    "        u /= np.sum(u)\n",
    "\n",
    "        classifiers.append((polarity, feature, threshold))\n",
    "        alphas.append(alpha)\n",
    "\n",
    "    return classifiers, alphas\n",
    "\n",
    "# Function to predict using AdaBoost\n",
    "def predict_adaboost(classifiers, alphas, X):\n",
    "    T = len(classifiers)\n",
    "    y_pred = np.zeros(X.shape[0])\n",
    "\n",
    "    for t in range(T):\n",
    "        polarity, feature, threshold = classifiers[t]\n",
    "        y_pred += alphas[t] * predict_stump(X, polarity, feature, threshold)\n",
    "\n",
    "    return np.sign(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of iterations\n",
    "T = 1000\n",
    "\n",
    "# Run AdaBoost-Stump\n",
    "classifiers, alphas = adaboost_stump(X_train_binary, y_train_binary, T)\n",
    "# Calculate Ein and Eout\n",
    "y_train_pred = predict_adaboost(classifiers, alphas, X_train_binary)\n",
    "y_test_pred = predict_adaboost(classifiers, alphas, X_test_binary)\n",
    "\n",
    "# Calculate Ein^u for each weak learner\n",
    "count = 0\n",
    "Ein_u = []\n",
    "for t in range(T):\n",
    "    polarity, feature, threshold = classifiers[t]\n",
    "    y_pred = predict_stump(X_train_binary, polarity, feature, threshold)\n",
    "    Ein_u.append(calculate_weighted_error(y_train_binary, y_pred, u))\n",
    "    count += 1\n",
    "    print(count)\n",
    "    \n",
    "# Calculate Ein\n",
    "Ein = np.mean(y_train_pred != y_train_binary)\n",
    "# Calculate Eout\n",
    "Eout = np.mean(y_test_pred != y_test_binary)\n",
    "\n",
    "# Q1. Value of min_{1≤t≤1000} Ein(gt)\n",
    "min_Ein_gt = min(Ein_u)\n",
    "# Q2. Value of max_{1≤t≤1000} Ein(gt)\n",
    "max_Ein_gt = max(Ein_u)\n",
    "# Q3. Value of Ein(G)\n",
    "Ein_G = Ein\n",
    "# Q4. Value of Eout(G)\n",
    "Eout_G = Eout\n",
    "\n",
    "print(\"Q1. min_{1≤t≤1000} Ein(gt):\", min_Ein_gt)\n",
    "print(\"Q2. max_{1≤t≤1000} Ein(gt):\", max_Ein_gt)\n",
    "print(\"Q3. Ein(G):\", Ein_G)\n",
    "print(\"Q4. Eout(G):\", Eout_G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n = 54, the result is: 0.7383207504875464\n",
      "For n = 56, the result is: 0.7634811530750749\n",
      "For n = 58, the result is: 0.7870204378161495\n",
      "For n = 60, the result is: 0.8089342809720512\n"
     ]
    }
   ],
   "source": [
    "N = 1126\n",
    "def calculate_result(n):\n",
    "    result = 1\n",
    "    for i in range(1, n + 1):\n",
    "        result *= (1 - i/N)\n",
    "    result = 1 - result\n",
    "    return result\n",
    "\n",
    "# Perform the comparison for the given values of n\n",
    "values_of_n = [54, 56, 58, 60]\n",
    "for n in values_of_n:\n",
    "    result = calculate_result(n)\n",
    "    print(f\"For n = {n}, the result is: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
