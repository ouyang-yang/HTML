{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from liblinear.liblinearutil import *\n",
    "import itertools\n",
    "from scipy.sparse import lil_matrix\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 11)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"ML_HW4_data_train.dat\", sep = \"\\t\", header = None)\n",
    "df.insert(loc=0, column=\"x0\", value=1)\n",
    "df.columns =['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'sign']\n",
    "X = df.iloc[:, :-1].to_numpy()\n",
    "y = df.iloc[:, -1].to_numpy()\n",
    "print(X.shape)\n",
    "\n",
    "df_test = pd.read_csv(\"ML_HW4_data_test.dat\", sep = \"\\t\", header = None)\n",
    "df_test.insert(loc=0, column=\"x0\", value=1)\n",
    "X_t = df_test.iloc[:, :-1].to_numpy()\n",
    "y_test = df_test.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polynomial Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X, degree):\n",
    "    n_samples, n_features = X.shape\n",
    "    combinations = list(itertools.combinations(range(n_features + degree - 1), degree))\n",
    "    n_output_features = len(combinations)\n",
    "    X_poly = np.empty((n_samples, n_output_features))\n",
    "    for i, comb in enumerate(combinations):\n",
    "        indices = np.array(list(comb)) - np.arange(degree)\n",
    "        X_poly[:, i] = np.prod(X[:, indices], axis=1)\n",
    "    return X_poly\n",
    "\n",
    "X_train = polynomial_features(X, 4)\n",
    "X_test = polynomial_features(X_t, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-06, 0.001, 1, 1000, 1000000]\n",
      "Accuracy = 77.4% (387/500) (classification)\n",
      "Accuracy = 82.2% (411/500) (classification)\n",
      "Accuracy = 84.6% (423/500) (classification)\n",
      "Accuracy = 85.8% (429/500) (classification)\n",
      "Accuracy = 81.2% (406/500) (classification)\n",
      "2.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "lambdas = [-6, -3, 0, 3, 6]\n",
    "for i in range(len(lambdas)):\n",
    "    lambdas[i] = 10**lambdas[i]\n",
    "print(lambdas)\n",
    "    \n",
    "# Evaluate the out-of-sample error for each value of lambda\n",
    "Eout = []\n",
    "for i in range(len(lambdas)):\n",
    "    param = f'-s 0 -c {1/(2*lambdas[i])} -e 0.000001 -q'\n",
    "    model = train(y, X_train, param)\n",
    "    p_label, p_acc, p_vals = predict(y_test, X_test, model)\n",
    "    predictions = [1 if pred > 0 else -1 for pred in p_label]\n",
    "    Eout.append(np.mean(predictions != y_test))\n",
    "\n",
    "# Select the best value of lambda\n",
    "best_lambda = lambdas[np.argmin(Eout)]\n",
    "print(math.log(best_lambda, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-06, 0.001, 1, 1000, 1000000]\n",
      "Accuracy = 75.8% (379/500) (classification)\n",
      "Accuracy = 83.8% (419/500) (classification)\n",
      "Accuracy = 84.6% (423/500) (classification)\n",
      "Accuracy = 68% (340/500) (classification)\n",
      "Accuracy = 49.2% (246/500) (classification)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "lambdas = [-6, -3, 0, 3, 6]\n",
    "for i in range(len(lambdas)):\n",
    "    lambdas[i] = 10**lambdas[i]\n",
    "print(lambdas)\n",
    "    \n",
    "# Evaluate the out-of-sample error for each value of lambda\n",
    "Eout = []\n",
    "for i in range(len(lambdas)):\n",
    "    param = f'-s 6 -c {1/(lambdas[i])} -e 0.000001 -q'\n",
    "    model = train(y, X_train, param)\n",
    "    p_label, p_acc, p_valS = predict(y_test, X_test, model)\n",
    "    predictions = [1 if pred > 0 else -1 for pred in p_label]\n",
    "    Eout.append(np.mean(predictions != y_test))\n",
    "\n",
    "# Select the best value of lambda\n",
    "best_lambda = lambdas[np.argmin(Eout)]\n",
    "print(math.log(best_lambda, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-06, 0.001, 1, 1000, 1000000]\n",
      "Accuracy = 100% (200/200) (classification)\n",
      "Accuracy = 100% (200/200) (classification)\n",
      "Accuracy = 100% (200/200) (classification)\n",
      "Accuracy = 96% (192/200) (classification)\n",
      "Accuracy = 76% (152/200) (classification)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "lambdas = [-6, -3, 0, 3, 6]\n",
    "for i in range(len(lambdas)):\n",
    "    lambdas[i] = 10**lambdas[i]\n",
    "print(lambdas)\n",
    "    \n",
    "# Evaluate the out-of-sample error for each value of lambda\n",
    "Ein = []\n",
    "for i in range(len(lambdas)):\n",
    "    param = f'-s 0 -c {1/(2*lambdas[i])} -e 0.000001 -q'\n",
    "    model = train(y, X_train, param)\n",
    "    p_label, p_acc, p_valS = predict(y, X_train, model)\n",
    "    predictions = [1 if pred > 0 else -1 for pred in p_label]\n",
    "    Ein.append(np.mean(predictions != y))\n",
    "\n",
    "# Select the best value of lambda\n",
    "best_lambda = lambdas[np.argmin(Eout)]\n",
    "print(math.log(best_lambda, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955\n"
     ]
    }
   ],
   "source": [
    "sparsity = 0\n",
    "param = f'-s 6 -c 0.5 -e 0.000001 -q'\n",
    "model = train(y, X_train, param)\n",
    "w = np.array(model.get_decfun()[0])\n",
    "sparsity = np.sum(abs(w)<= 10**(-6))\n",
    "print(sparsity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sparsity = 0\n",
    "param = f'-s 0 -c 0.0005 -e 0.000001 -q'\n",
    "model = train(y, X_train, param)\n",
    "w = np.array(model.get_decfun()[0])\n",
    "sparsity = np.sum(abs(w)<= 10**(-6))\n",
    "print(sparsity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-06, 0.001, 1, 1000, 1000000]\n",
      "[2, 16, 82, 153, 3]\n",
      "Lambda that is selected the most often: 1000\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "def train_test_split(X, y, test_size=0.4, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    n_samples = X.shape[0]\n",
    "    n_test = int(test_size * n_samples)\n",
    "    test_indices = rng.choice(n_samples, n_test, replace=False)\n",
    "    train_indices = np.delete(np.arange(n_samples), test_indices)\n",
    "    \n",
    "    X_train = X[train_indices]\n",
    "    X_val = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_val = y[test_indices]\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "l=[-6,-3,0,3,6]\n",
    "lambdas = [-6, -3, 0, 3, 6]\n",
    "for i in range(len(lambdas)):\n",
    "    lambdas[i] = 10**lambdas[i]\n",
    "print(lambdas)\n",
    "\n",
    "Eout = []\n",
    "count_best_lambda = [0] * len(lambdas)\n",
    "num_iter = 256\n",
    "for t in range(num_iter):\n",
    "    b_acc = 0\n",
    "    bl = -1\n",
    "    Eval = []\n",
    "    Xv_train, X_val, yv_train, y_val = train_test_split(X_train, y)\n",
    "    for i in range(len(lambdas)):\n",
    "        param = f'-s 0 -c {1/(2*lambdas[i])} -e 0.000001 -q'\n",
    "        model = train(yv_train, Xv_train, param) \n",
    "        p_label, p_acc, p_vals = predict(y_val, X_val, model, '-q')\n",
    "        #print(b_acc,p_acc[0])\n",
    "        if b_acc<=p_acc[0]:\n",
    "            b_acc=p_acc[0]\n",
    "            bl = l[i]\n",
    "            #print(bl)\n",
    "            \n",
    "        predictions = [1 if pred > 0 else -1 for pred in p_label]\n",
    "        Eval.append(np.mean(predictions != y_val))\n",
    "    # Select the best value of lambda\n",
    "    #best_lambda_idx = np.argmin(Eval)\n",
    "    #count_best_lambda[best_lambda_idx] += 1\n",
    "    count_best_lambda[l.index(bl)] += 1\n",
    "    best_param = f'-s 0 -c {1/(2*lambdas[l.index(bl)])} -e 0.000001 -q'\n",
    "    #best_param = f'-s 0 -c {1/(2*lambdas[best_lambda_idx])} -e 0.000001 -q'\n",
    "    new_model = train(yv_train, Xv_train, best_param) \n",
    "    pn_label, pn_acc, pn_vals = predict(y_test, X_test, new_model,'-q')\n",
    "\n",
    "    Eout.append(1-pn_acc[0]/100)\n",
    "\n",
    "print(count_best_lambda)\n",
    "best_lambda_idx = np.argmax(count_best_lambda)\n",
    "best_lambda = lambdas[best_lambda_idx]\n",
    "print(\"Lambda that is selected the most often:\", best_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1687734375\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(Eout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-b30ce3367e1a>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  Etemp.append(np.mean(predictions != y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "Eout = []\n",
    "num_iter = 256\n",
    "for t in range(num_iter):\n",
    "    Etemp = []\n",
    "    Xv_train, X_val, yv_train, y_val = train_test_split(X_train, y)\n",
    "    for i in range(len(lambdas)):\n",
    "        param = f'-s 0 -c {1/(2*lambdas[i])} -e 0.000001 -q'\n",
    "        model = train(yv_train, Xv_train, param) \n",
    "        p_label, p_acc, p_vals = predict(y_val, X_val, model, '-q')\n",
    "        predictions = [1 if pred > 0 else -1 for pred in p_label]\n",
    "        Etemp.append(np.mean(predictions != y_test))\n",
    "    # Select the best value of lambda\n",
    "    best_lambda_idx = np.argmin(Etemp)\n",
    "    Eout.append(np.min(Etemp))\n",
    "    \n",
    "print(np.mean(Eout))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18999999999999997\n"
     ]
    }
   ],
   "source": [
    "Eout = []\n",
    "num_iter = 256\n",
    "for t in range(num_iter):\n",
    "    param = f'-s 0 -c {1/(2*1000)} -e 0.000001 -q'\n",
    "    model = train(yv_train, Xv_train, param) \n",
    "    p_label, p_acc, p_vals = predict(y_test, X_test, model, '-q')\n",
    "    predictions = [1 if pred > 0 else -1 for pred in p_label]\n",
    "    Eout.append(np.mean(predictions != y_test))\n",
    "\n",
    "print(np.mean(Eout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-06, 0.001, 1, 1000, 1000000]\n",
      "[2, 13, 77, 162, 2]\n",
      "Lambda that is selected the most often: 1000\n",
      "Eout =  0.14845312499999996\n"
     ]
    }
   ],
   "source": [
    "l=[-6,-3,0,3,6]\n",
    "lambdas = [-6, -3, 0, 3, 6]\n",
    "for i in range(len(lambdas)):\n",
    "    lambdas[i] = 10**lambdas[i]\n",
    "print(lambdas)\n",
    "\n",
    "Eout = []\n",
    "count_best_lambda = [0] * len(lambdas)\n",
    "num_iter = 256\n",
    "for t in range(num_iter):\n",
    "    b_acc = 0\n",
    "    bl = -1\n",
    "    Eval = []\n",
    "    Xv_train, X_val, yv_train, y_val = train_test_split(X_train, y)\n",
    "    for i in range(len(lambdas)):\n",
    "        param = f'-s 0 -c {1/(2*lambdas[i])} -e 0.000001 -q'\n",
    "        model = train(yv_train, Xv_train, param) \n",
    "        p_label, p_acc, p_vals = predict(y_val, X_val, model, '-q')\n",
    "        #print(b_acc,p_acc[0])\n",
    "        if b_acc<=p_acc[0]:\n",
    "            b_acc=p_acc[0]\n",
    "            bl = l[i]\n",
    "            #print(bl)\n",
    "            \n",
    "        predictions = [1 if pred > 0 else -1 for pred in p_label]\n",
    "        Eval.append(np.mean(predictions != y_val))\n",
    "    # Select the best value of lambda\n",
    "    #best_lambda_idx = np.argmin(Eval)\n",
    "    #count_best_lambda[best_lambda_idx] += 1\n",
    "    count_best_lambda[l.index(bl)] += 1\n",
    "    best_param = f'-s 0 -c {1/(2*lambdas[l.index(bl)])} -e 0.000001 -q'\n",
    "    #best_param = f'-s 0 -c {1/(2*lambdas[best_lambda_idx])} -e 0.000001 -q'\n",
    "    new_model = train(y, X_train, best_param) \n",
    "    pn_label, pn_acc, pn_vals = predict(y_test, X_test, new_model,'-q')\n",
    "    #new_predictions = [1 if pred > 0 else -1 for pred in pn_label]\n",
    "    #print(pn_acc)\n",
    "    Eout.append(1-pn_acc[0]/100)\n",
    "\n",
    "print(count_best_lambda)\n",
    "best_lambda_idx = np.argmax(count_best_lambda)\n",
    "best_lambda = lambdas[best_lambda_idx]\n",
    "print(\"Lambda that is selected the most often:\", best_lambda)\n",
    "print(\"Eout = \", np.mean(Eout))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-06, 0.001, 1, 1000, 1000000]\n",
      "[4, 6, 70, 171, 5]\n",
      "Lambda that is selected the most often: 3\n",
      "average Ecv =  0.11464843749999999\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "\n",
    "l=[-6,-3,0,3,6]\n",
    "lambdas = [-6, -3, 0, 3, 6]\n",
    "for i in range(len(lambdas)):\n",
    "    lambdas[i] = 10**lambdas[i]\n",
    "print(lambdas)\n",
    "\n",
    "avgEcv = []\n",
    "count_best_lambda = [0] * len(lambdas)\n",
    "num_iter = 256\n",
    "for t in range(num_iter):\n",
    "    b_acc = 0\n",
    "    bl = -1\n",
    "    Ecv = []\n",
    "\n",
    "    # Generate a random permutation of the indices\n",
    "    indices = rng.permutation(X_train.shape[0])\n",
    "    # Split the indices into n_folds equal parts\n",
    "    fold_indices = np.array_split(indices, n_folds)\n",
    "\n",
    "    # Loop over the folds\n",
    "    for i in range(n_folds):\n",
    "        # Split the data into training and validation sets\n",
    "        val_indices = fold_indices[i]\n",
    "        train_indices = np.concatenate([fold_indices[j] for j in range(n_folds) if j != i])\n",
    "        Xv_train, yv_train = X_train[train_indices, :-1], y[train_indices]\n",
    "        X_val, y_val = X_train[val_indices, :-1], y[val_indices]\n",
    "    \n",
    "    for i in range(len(lambdas)):\n",
    "        param = f'-s 0 -c {1/(2*lambdas[i])} -e 0.000001 -q'\n",
    "        model = train(yv_train, Xv_train, param) \n",
    "        p_label, p_acc, p_vals = predict(y_val, X_val, model, '-q')\n",
    "        if b_acc<=p_acc[0]:\n",
    "            b_acc=p_acc[0]\n",
    "            bl = l[i]\n",
    "            \n",
    "        predictions = [1 if pred > 0 else -1 for pred in p_label]\n",
    "        Ecv.append(np.mean(predictions != y_val))\n",
    "    \n",
    "    # Select the best value of lambda\n",
    "    count_best_lambda[l.index(bl)] += 1\n",
    "    best_param = f'-s 0 -c {1/(2*lambdas[l.index(bl)])} -e 0.000001 -q'\n",
    "    new_model = train(yv_train, Xv_train, best_param) \n",
    "    pn_label, pn_acc, pn_vals = predict(y_val, X_val, new_model,'-q')\n",
    "    avgEcv.append(1-pn_acc[0]/100)\n",
    "\n",
    "print(count_best_lambda)\n",
    "best_lambda_idx = np.argmax(count_best_lambda)\n",
    "best_lambda = lambdas[best_lambda_idx]\n",
    "print(\"Lambda that is selected the most often:\", bl)\n",
    "print(\"average Ecv = \", np.mean(avgEcv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
