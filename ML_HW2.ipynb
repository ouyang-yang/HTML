{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13~16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-8d982ff13f0b>:64: RuntimeWarning: invalid value encountered in subtract\n",
      "  error_idx = np.where((s == np.array([-1, 1])))[0][0] * len(theta_vals) + np.abs(theta_vals - theta).argmin()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Eout(g, tau) - Ein(g) over 10000 trials: 0.0143875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment(sample_size, tau):\n",
    "    rng = np.random.default_rng()\n",
    "    # Generate random array x and compute y\n",
    "    x = rng.uniform(-0.5, 0.5, sample_size)\n",
    "    x.sort()\n",
    "    def my_sign(x):\n",
    "        return np.sign(np.where(x != 0, x, -1))\n",
    "    y = my_sign(x)\n",
    "\n",
    "    def flip_labels(y, tau):\n",
    "        if tau > 0:\n",
    "            random_vals = np.random.random(size=y.shape)\n",
    "            flip_indices = random_vals <= tau\n",
    "            y_flipped = y.copy()\n",
    "            y_flipped[flip_indices] *= -1\n",
    "            return y_flipped\n",
    "        else:\n",
    "            return y\n",
    "\n",
    "\n",
    "    # Flip y to -y with probability tau\n",
    "    y = flip_labels(y, tau)\n",
    "\n",
    "    # Generate new random array x and compute y\n",
    "    x_new = rng.uniform(-0.5, 0.5, sample_size)\n",
    "    x_new.sort()\n",
    "    y_new = my_sign(x_new)\n",
    "    y_new = flip_labels(y_new, tau)\n",
    "\n",
    "    # Define the hypothesis h\n",
    "    def h(x, s, theta):\n",
    "        return s * np.sign(x - theta)\n",
    "\n",
    "    # Compute possible values of theta\n",
    "    unique_x = np.unique(x)\n",
    "    diffs = np.diff(unique_x)\n",
    "    if len(diffs) == 0:\n",
    "        theta_vals = [-np.inf, np.inf]\n",
    "    else:\n",
    "        theta_vals = np.hstack(([-np.inf], unique_x[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "\n",
    "    # Compute Ein(h) for all combinations of s and theta\n",
    "    misclassified = []\n",
    "    for s in [-1, 1]:\n",
    "        for theta in theta_vals:\n",
    "            predictions = h(x, s, theta)\n",
    "            misclassified.append((predictions != y).sum())\n",
    "\n",
    "    # Compute the minimum misclassification error and corresponding s and theta\n",
    "    min_error_idx = np.argmin(misclassified)\n",
    "    min_error = misclassified[min_error_idx]\n",
    "    min_error_s = [-1, 1][min_error_idx // len(theta_vals)]\n",
    "    min_error_theta = theta_vals[min_error_idx % len(theta_vals)]\n",
    "\n",
    "    # Return the hypothesis with the minimum Ein as g; break ties by smallest s * theta\n",
    "    g = h(x, min_error_s, min_error_theta)\n",
    "    for s in [-1, 1]:\n",
    "        for theta in theta_vals:\n",
    "            if s == min_error_s and theta == min_error_theta:\n",
    "                continue\n",
    "            error_idx = np.where((s == np.array([-1, 1])))[0][0] * len(theta_vals) + np.abs(theta_vals - theta).argmin()\n",
    "            if misclassified[error_idx] == min_error and s * theta < min_error_s * min_error_theta:\n",
    "                g = h(x, s, theta)\n",
    "                min_error_s = s\n",
    "                min_error_theta = theta\n",
    "\n",
    "    Ein_g = min_error / len(x)\n",
    "    Eout_g = np.mean(h(x_new, min_error_s, min_error_theta) != y_new)\n",
    "    return Eout_g - Ein_g\n",
    "\n",
    "n_trials = 10000\n",
    "sample_size = 128\n",
    "tau = 0.2   # Set probability of flipping\n",
    "results = [experiment(sample_size, tau) for i in range(n_trials)]\n",
    "mean_diff = np.mean(results)\n",
    "\n",
    "print(\"Mean of Eout(g, tau) - Ein(g) over\", n_trials, \"trials:\", mean_diff)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17、18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "y_train = df_train.iloc[:, -1].to_numpy()\n",
    "sample_size_train = df_train.shape[0]\n",
    "\n",
    "df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "y_test = df_test.iloc[:, -1].to_numpy()\n",
    "sample_size_test = df_test.shape[0]\n",
    "X_train_idx = X_train.shape[0]\n",
    "y_train_idx = y_train.shape[0]\n",
    "print(X_train_idx)\n",
    "print(y_train_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 先小修13~16的code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (192,) (187,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-ad53e5c0b1b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mEin_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEout_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEout_g\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mEin_g\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0mEin_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEout_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEout_Ein_diff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Ein(g): {Ein_g:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Eout(g): {Eout_g:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-ad53e5c0b1b5>\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtheta_vals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mmisclassified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-ad53e5c0b1b5>\u001b[0m in \u001b[0;36mh\u001b[1;34m(X, s, theta)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Define the hypothesis h\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_theta_vals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (192,) (187,) "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment():\n",
    "\n",
    "    df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "    X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "    y_train = df_train.iloc[:, -1].to_numpy()\n",
    "    sample_size_train = df_train.shape[0]\n",
    "\n",
    "    df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "    X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "    y_test = df_test.iloc[:, -1].to_numpy()\n",
    "    sample_size_test = df_test.shape[0]\n",
    "\n",
    "    # Define the hypothesis h\n",
    "    def h(X, s, theta):\n",
    "        return s * np.sign(X[:, 0] - theta)\n",
    "\n",
    "    def compute_theta_vals(X_train):\n",
    "        theta_vals = []\n",
    "        for col in range(X_train.shape[1]):\n",
    "            unique_x = np.unique(X_train[:,col])\n",
    "            diffs = np.diff(unique_x)\n",
    "            if len(diffs) == 0:\n",
    "                theta_vals_col = [-np.inf, np.inf]\n",
    "            else:\n",
    "                theta_vals_col = np.hstack(([-np.inf], unique_x[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "            theta_vals.append(theta_vals_col)\n",
    "        return theta_vals\n",
    "\n",
    "\n",
    "    theta_vals = compute_theta_vals(X_train)\n",
    "\n",
    "    # Compute Ein(h) for all combinations of s and theta\n",
    "    misclassified = []\n",
    "    for s in [-1, 1]:\n",
    "        for theta in theta_vals:\n",
    "            predictions = h(X_train, s, theta)\n",
    "            misclassified.append((predictions != y_train).sum())\n",
    "\n",
    "    # Compute the minimum misclassification error and corresponding s and theta\n",
    "    min_error_idx = np.argmin(misclassified)\n",
    "    min_error = misclassified[min_error_idx]\n",
    "    min_error_s = [-1, 1][min_error_idx // len(theta_vals)]\n",
    "    min_error_theta = theta_vals[min_error_idx % len(theta_vals)]\n",
    "\n",
    "    # Return the hypothesis with the minimum Ein as g; break ties by smallest s * theta\n",
    "    g = h(X_train, min_error_s, min_error_theta)\n",
    "    for s in [-1, 1]:\n",
    "        for theta in theta_vals:\n",
    "            if s == min_error_s and theta == min_error_theta:\n",
    "                continue\n",
    "            error_idx = np.where((s == np.array([-1, 1])))[0][0] * len(theta_vals) + np.abs(theta_vals - theta).argmin()\n",
    "            if misclassified[error_idx] == min_error and s * theta < min_error_s * min_error_theta:\n",
    "                g = h(x, s, theta)\n",
    "                min_error_s = s\n",
    "                min_error_theta = theta\n",
    "\n",
    "    Ein_g = min_error / len(x)\n",
    "    Eout_g = np.mean(h(x_test, min_error_s, min_error_theta) != y_test)\n",
    "\n",
    "\n",
    "    return Ein_g, Eout_g, Eout_g - Ein_g\n",
    "\n",
    "Ein_g, Eout_g, Eout_Ein_diff = experiment()\n",
    "print(f\"Ein(g): {Ein_g:.2f}\")\n",
    "print(f\"Eout(g): {Eout_g:.2f}\")\n",
    "print(f\"Eout(g) - Ein(g): {Eout_Ein_diff:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def decision_stump(X, y):\n",
    "    n, d = X.shape\n",
    "    misclassified = np.zeros((2*d, n))\n",
    "    thetas = np.zeros((2*d, d))\n",
    "    for i in range(d):\n",
    "        idx = np.argsort(X[:,i])\n",
    "        X_i = X[idx,i]\n",
    "        y_i = y[idx]\n",
    "        thetas[2*i, i] = X_i[0] - 1.0\n",
    "        thetas[2*i+1, i] = X_i[-1] + 1.0\n",
    "        for j in range(n-1):\n",
    "            thetas[2*i+j+2, i] = (X_i[j] + X_i[j+1]) / 2.0\n",
    "        for s in [-1, 1]:\n",
    "            for j in range(2*n):\n",
    "                y_pred = s * np.sign(X[:,i] - thetas[j,i])\n",
    "                misclassified[j,:] += y_pred != y\n",
    "    min_error_idx = np.argmin(misclassified)\n",
    "    min_error = misclassified.flatten()[min_error_idx]\n",
    "    min_error_s = [-1, 1][min_error_idx // n // d]\n",
    "    min_error_thetas = thetas[min_error_idx // n % d]\n",
    "    g = lambda x: min_error_s * np.sign(x - min_error_thetas)\n",
    "    return g, min_error / n\n",
    "\n",
    "def experiment():\n",
    "    df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "    # Extract features and labels\n",
    "    X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "    y_train = df_train.iloc[:, -1].to_numpy()\n",
    "    sample_size_train = df_train.shape[0]\n",
    "\n",
    "    df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "    # Extract features and labels\n",
    "    X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "    y_test = df_test.iloc[:, -1].to_numpy()\n",
    "    sample_size_test = df_test.shape[0]\n",
    "\n",
    "    # Find the best decision stump using the training data\n",
    "    g, Ein = decision_stump(X_train, y_train)\n",
    "\n",
    "    # Compute the test error Eout\n",
    "    Eout = np.mean(g(X_test) != y_test)\n",
    "\n",
    "    return Ein_g, Eout_g, Eout_g - Ein_g\n",
    "\n",
    "Ein_g, Eout_g, Eout_Ein_diff = experiment()\n",
    "print(f\"Ein(g): {Ein_g:.2f}\")\n",
    "print(f\"Eout(g): {Eout_g:.2f}\")\n",
    "print(f\"Eout(g) - Ein(g): {Eout_Ein_diff:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (192,10) (192,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a53e6cfaf382>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mEin_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEout_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEout_g\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mEin_g\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mEin_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEout_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEout_Ein_diff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Ein(g): {Ein_g:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Eout(g): {Eout_g:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-a53e6cfaf382>\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mEout_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtheta_vals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mEin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mEout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mEin_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (192,10) (192,) "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment():\n",
    "    df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "    X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "    y_train = df_train.iloc[:, -1].to_numpy()\n",
    "    sample_size_train = df_train.shape[0]\n",
    "\n",
    "    df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "    X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "    y_test = df_test.iloc[:, -1].to_numpy()\n",
    "    sample_size_test = df_test.shape[0]\n",
    "\n",
    "    def h(x, s, theta):\n",
    "        predictions = s * np.sign(x - theta)\n",
    "        return predictions\n",
    "\n",
    "    # Compute possible values of theta\n",
    "    unique_X_train = np.unique(X_train)\n",
    "    diffs = np.diff(unique_X_train)\n",
    "    if len(diffs) == 0:\n",
    "        theta_vals = [-np.inf, np.inf]\n",
    "    else:\n",
    "        theta_vals = np.hstack(([-np.inf], unique_X_train[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "\n",
    "    # Compute Ein(h) and Eout(h) for all thresholds\n",
    "    Ein_vals = []\n",
    "    Eout_vals = []\n",
    "    for theta in theta_vals:\n",
    "        Ein = np.mean(np.not_equal(h(X_train, 1, theta), y_train))\n",
    "        Eout = np.mean(np.not_equal(h(X_test, 1, theta), y_test))\n",
    "        Ein_vals.append(Ein)\n",
    "        Eout_vals.append(Eout)\n",
    "\n",
    "    # Find the threshold that minimizes Eout(h)\n",
    "    min_Eout_idx = np.argmin(Eout_vals)\n",
    "    min_Eout = Eout_vals[min_Eout_idx]\n",
    "    min_Eout_theta = theta_vals[min_Eout_idx]\n",
    "\n",
    "    # Compute the corresponding Ein(h) and Eout(g)\n",
    "    min_Ein = Ein_vals[min_Eout_idx]\n",
    "    Eout_g = min_Eout\n",
    "    Ein_g = min_Ein\n",
    "    return Ein_g, Eout_g, Eout_g - Ein_g\n",
    "\n",
    "Ein_g, Eout_g, Eout_Ein_diff = experiment()\n",
    "print(f\"Ein(g): {Ein_g:.2f}\")\n",
    "print(f\"Eout(g): {Eout_g:.2f}\")\n",
    "print(f\"Eout(g) - Ein(g): {Eout_Ein_diff:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 有跑出來，但是是錯的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein(g): 0.33\n",
      "Eout(g): 0.42\n",
      "Eout(g) - Ein(g): 0.09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment():\n",
    "    df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "    X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "    y_train = df_train.iloc[:, -1].to_numpy()\n",
    "    sample_size_train = df_train.shape[0]\n",
    "\n",
    "    df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "    X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "    y_test = df_test.iloc[:, -1].to_numpy()\n",
    "    sample_size_test = df_test.shape[0]\n",
    "\n",
    "    def h(x, s, theta):\n",
    "        predictions = np.zeros_like(x)\n",
    "        for i in range(len(x)):\n",
    "            predictions[i] = s * np.sign(x[i] - theta)\n",
    "        return predictions\n",
    "\n",
    "    # Compute possible values of theta\n",
    "    unique_X_train = np.unique(X_train)\n",
    "    diffs = np.diff(unique_X_train)\n",
    "    if len(diffs) == 0:\n",
    "        theta_vals = [-np.inf, np.inf]\n",
    "    else:\n",
    "        theta_vals = np.hstack(([-np.inf], unique_X_train[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "\n",
    "    # Compute Ein(h) for all values of s and theta\n",
    "    min_error = np.inf\n",
    "    min_error_s = None\n",
    "    min_error_theta = None\n",
    "    min_error_i = None\n",
    "\n",
    "    for s in [-1, 1]:\n",
    "        for i, theta in enumerate(theta_vals):\n",
    "            predictions = h(X_train, s, theta)\n",
    "            error = np.sum(np.not_equal(predictions.reshape(-1,1), y_train))\n",
    "\n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                min_error_s = s\n",
    "                min_error_theta = theta\n",
    "                min_error_i = i\n",
    "\n",
    "    Ein_g = np.mean(np.not_equal(h(X_train, min_error_s, min_error_theta).reshape(-1, 1), y_train))\n",
    "    Eout_g = np.mean(np.not_equal(h(X_test, min_error_s, min_error_theta).reshape(-1, 1), y_test))\n",
    "\n",
    "    return Ein_g, Eout_g, Eout_g - Ein_g\n",
    "\n",
    "Ein_g, Eout_g, Eout_Ein_diff = experiment()\n",
    "print(f\"Ein(g): {Ein_g:.2f}\")\n",
    "print(f\"Eout(g): {Eout_g:.2f}\")\n",
    "print(f\"Eout(g) - Ein(g): {Eout_Ein_diff:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### best of best algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein(g1): 0.02604\n",
      "Eout(g1): 0.07812\n",
      "Eout(g1) - Ein(g1): 0.05208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment1():\n",
    "    df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "    X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "    y_train = df_train.iloc[:, -1].to_numpy()\n",
    "    sample_size_train = df_train.shape[0]\n",
    "    num_features = X_train.shape[1]\n",
    "\n",
    "    df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "    X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "    y_test = df_test.iloc[:, -1].to_numpy()\n",
    "    sample_size_test = df_test.shape[0]\n",
    "\n",
    "    best_hypothesis = None\n",
    "    min_error = np.inf\n",
    "\n",
    "    for i in range(num_features):\n",
    "        unique_X_train = np.unique(X_train[:, i])\n",
    "        diffs = np.diff(unique_X_train)\n",
    "        if len(diffs) == 0:\n",
    "            theta_vals = [-np.inf, np.inf]\n",
    "        else:\n",
    "            theta_vals = np.hstack(([-np.inf], unique_X_train[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "\n",
    "        for s in [-1, 1]:\n",
    "            for theta in theta_vals:\n",
    "                predictions = s * np.sign(X_train[:, i] - theta)\n",
    "                error = np.sum(np.not_equal(predictions, y_train))\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                    best_hypothesis = (i, s, theta)\n",
    "                elif error == min_error and i < best_hypothesis[0]:\n",
    "                    best_hypothesis = (i, s, theta)\n",
    "\n",
    "    def h(x):\n",
    "        i, s, theta = best_hypothesis\n",
    "        return s * np.sign(x[:, i] - theta)\n",
    "\n",
    "    Ein_g = np.mean(np.not_equal(h(X_train), y_train))\n",
    "    Eout_g = np.mean(np.not_equal(h(X_test), y_test))\n",
    "\n",
    "    return Ein_g, Eout_g, Eout_g - Ein_g\n",
    "\n",
    "Ein_g1, Eout_g1, Eout_Ein_diff1 = experiment1()\n",
    "print(f\"Ein(g1): {Ein_g1:.5f}\")\n",
    "print(f\"Eout(g1): {Eout_g1:.5f}\")\n",
    "print(f\"Eout(g1) - Ein(g1): {Eout_Ein_diff1:.5f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19、20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein(g): 0.32812\n",
      "Eout(g): 0.42188\n",
      "Eout(g) - Ein(g): 0.09375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment2():\n",
    "    df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "    X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "    y_train = df_train.iloc[:, -1].to_numpy()\n",
    "    sample_size_train = df_train.shape[0]\n",
    "    num_features = X_train.shape[1]\n",
    "\n",
    "    df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "    X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "    y_test = df_test.iloc[:, -1].to_numpy()\n",
    "    sample_size_test = df_test.shape[0]\n",
    "\n",
    "    best_hypotheses = [None] * num_features\n",
    "    min_errors = np.inf * np.ones(num_features)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        unique_X_train = np.unique(X_train[:, i])\n",
    "        diffs = np.diff(unique_X_train)\n",
    "        if len(diffs) == 0:\n",
    "            theta_vals = [-np.inf, np.inf]\n",
    "        else:\n",
    "            theta_vals = np.hstack(([-np.inf], unique_X_train[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "\n",
    "        for s in [-1, 1]:\n",
    "            for theta in theta_vals:\n",
    "                predictions = s * np.sign(X_train[:, i] - theta)\n",
    "                error = np.mean(np.not_equal(predictions, y_train))\n",
    "\n",
    "                if error < min_errors[i]:\n",
    "                    min_errors[i] = error\n",
    "                    best_hypotheses[i] = (i, s, theta)\n",
    "                elif error == min_errors[i] and i < best_hypotheses[i][0]:\n",
    "                    best_hypotheses[i] = (i, s, theta)\n",
    "\n",
    "    best_hypothesis = best_hypotheses[np.argmax(min_errors)]\n",
    "\n",
    "    def h(x):\n",
    "        i, s, theta = best_hypothesis\n",
    "        return s * np.sign(x[:, i] - theta)\n",
    "\n",
    "    Ein_g2 = np.mean(np.not_equal(h(X_train), y_train))\n",
    "    Eout_g2 = np.mean(np.not_equal(h(X_test), y_test))\n",
    "\n",
    "    return Ein_g, Eout_g, Eout_g - Ein_g\n",
    "\n",
    "Ein_g2, Eout_g2, Eout_Ein_diff2 = experiment2()\n",
    "print(f\"Ein(g2): {Ein_g2:.5f}\")\n",
    "print(f\"Eout(g2): {Eout_g2:.5f}\")\n",
    "print(f\"Eout(g2) - Ein(g2): {Eout_Ein_diff2:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_Ein =  0.30208\n",
      "delta_Eout =  0.34375\n"
     ]
    }
   ],
   "source": [
    "print(f\"delta_Ein = {Ein_g2 - Ein_g1:.5f}\")\n",
    "print(f\"delta_Eout = {Eout_g2 - Eout_g1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
