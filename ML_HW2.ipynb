{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13~16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment(sample_size, tau):\n",
    "    rng = np.random.default_rng()\n",
    "    # Generate random array x and compute y\n",
    "    x = rng.uniform(-0.5, 0.5, sample_size)\n",
    "    x.sort()\n",
    "    def my_sign(x):\n",
    "        return np.sign(np.where(x != 0, x, -1))\n",
    "    y = my_sign(x)\n",
    "\n",
    "    def flip_labels(y, tau):\n",
    "        if tau > 0:\n",
    "            random_vals = np.random.random(size=y.shape)\n",
    "            flip_indices = random_vals <= tau\n",
    "            y_flipped = y.copy()\n",
    "            y_flipped[flip_indices] *= -1\n",
    "            return y_flipped\n",
    "        else:\n",
    "            return y\n",
    "\n",
    "\n",
    "    # Flip y to -y with probability tau\n",
    "    y = flip_labels(y, tau)\n",
    "\n",
    "    # Generate new random array x and compute y\n",
    "    x_new = rng.uniform(-0.5, 0.5, sample_size)\n",
    "    x_new.sort()\n",
    "    y_new = my_sign(x_new)\n",
    "    y_new = flip_labels(y_new, tau)\n",
    "\n",
    "    # Define the hypothesis h\n",
    "    def h(x, s, theta):\n",
    "        return s * np.sign(x - theta)\n",
    "\n",
    "    # Compute possible values of theta\n",
    "    unique_x = np.unique(x)\n",
    "    diffs = np.diff(unique_x)\n",
    "    if len(diffs) == 0:\n",
    "        theta_vals = [-np.inf, np.inf]\n",
    "    else:\n",
    "        theta_vals = np.hstack(([-np.inf], unique_x[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "\n",
    "    # Compute Ein(h) for all combinations of s and theta\n",
    "    misclassified = []\n",
    "    for s in [-1, 1]:\n",
    "        for theta in theta_vals:\n",
    "            predictions = h(x, s, theta)\n",
    "            misclassified.append((predictions != y).sum())\n",
    "\n",
    "    # Compute the minimum misclassification error and corresponding s and theta\n",
    "    min_error_idx = np.argmin(misclassified)\n",
    "    min_error = misclassified[min_error_idx]\n",
    "    min_error_s = [-1, 1][min_error_idx // len(theta_vals)]\n",
    "    min_error_theta = theta_vals[min_error_idx % len(theta_vals)]\n",
    "\n",
    "    # Return the hypothesis with the minimum Ein as g; break ties by smallest s * theta\n",
    "    g = h(x, min_error_s, min_error_theta)\n",
    "    for s in [-1, 1]:\n",
    "        for theta in theta_vals:\n",
    "            if s == min_error_s and theta == min_error_theta:\n",
    "                continue\n",
    "            error_idx = np.where((s == np.array([-1, 1])))[0][0] * len(theta_vals) + np.abs(theta_vals - theta).argmin()\n",
    "            if misclassified[error_idx] == min_error and s * theta < min_error_s * min_error_theta:\n",
    "                g = h(x, s, theta)\n",
    "                min_error_s = s\n",
    "                min_error_theta = theta\n",
    "\n",
    "    Ein_g = min_error / len(x)\n",
    "    Eout_g = np.mean(h(x_new, min_error_s, min_error_theta) != y_new)\n",
    "    return Eout_g - Ein_g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-9c2b50ed4a7d>:64: RuntimeWarning: invalid value encountered in subtract\n",
      "  error_idx = np.where((s == np.array([-1, 1])))[0][0] * len(theta_vals) + np.abs(theta_vals - theta).argmin()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Eout(g, tau) - Ein(g) over 10000 trials: 0.2945\n"
     ]
    }
   ],
   "source": [
    "n_trials = 10000\n",
    "sample_size = 2\n",
    "tau = 0   # Set probability of flipping\n",
    "results = [experiment(sample_size, tau) for i in range(n_trials)]\n",
    "mean_diff = np.mean(results)\n",
    "\n",
    "print(\"Mean of Eout(g, tau) - Ein(g) over\", n_trials, \"trials:\", mean_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-9c2b50ed4a7d>:64: RuntimeWarning: invalid value encountered in subtract\n",
      "  error_idx = np.where((s == np.array([-1, 1])))[0][0] * len(theta_vals) + np.abs(theta_vals - theta).argmin()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Eout(g, tau) - Ein(g) over 10000 trials: 0.00369765625\n"
     ]
    }
   ],
   "source": [
    "n_trials = 10000\n",
    "sample_size = 128\n",
    "tau = 0   # Set probability of flipping\n",
    "results = [experiment(sample_size, tau) for i in range(n_trials)]\n",
    "mean_diff = np.mean(results)\n",
    "\n",
    "print(\"Mean of Eout(g, tau) - Ein(g) over\", n_trials, \"trials:\", mean_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-9c2b50ed4a7d>:64: RuntimeWarning: invalid value encountered in subtract\n",
      "  error_idx = np.where((s == np.array([-1, 1])))[0][0] * len(theta_vals) + np.abs(theta_vals - theta).argmin()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Eout(g, tau) - Ein(g) over 10000 trials: 0.42845\n"
     ]
    }
   ],
   "source": [
    "n_trials = 10000\n",
    "sample_size = 2\n",
    "tau = 0.2   # Set probability of flipping\n",
    "results = [experiment(sample_size, tau) for i in range(n_trials)]\n",
    "mean_diff = np.mean(results)\n",
    "\n",
    "print(\"Mean of Eout(g, tau) - Ein(g) over\", n_trials, \"trials:\", mean_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-9c2b50ed4a7d>:64: RuntimeWarning: invalid value encountered in subtract\n",
      "  error_idx = np.where((s == np.array([-1, 1])))[0][0] * len(theta_vals) + np.abs(theta_vals - theta).argmin()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Eout(g, tau) - Ein(g) over 10000 trials: 0.01409140625\n"
     ]
    }
   ],
   "source": [
    "n_trials = 10000\n",
    "sample_size = 128\n",
    "tau = 0.2   # Set probability of flipping\n",
    "results = [experiment(sample_size, tau) for i in range(n_trials)]\n",
    "mean_diff = np.mean(results)\n",
    "\n",
    "print(\"Mean of Eout(g, tau) - Ein(g) over\", n_trials, \"trials:\", mean_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17、18"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### best of best algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein(g1): 0.02604\n",
      "Eout(g1): 0.07812\n",
      "Eout(g1) - Ein(g1): 0.05208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment1():\n",
    "    df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "    X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "    y_train = df_train.iloc[:, -1].to_numpy()\n",
    "    sample_size_train = df_train.shape[0]\n",
    "    num_features = X_train.shape[1]\n",
    "\n",
    "    df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "    X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "    y_test = df_test.iloc[:, -1].to_numpy()\n",
    "    sample_size_test = df_test.shape[0]\n",
    "\n",
    "    best_hypothesis = None\n",
    "    min_error = np.inf\n",
    "\n",
    "    for i in range(num_features):\n",
    "        unique_X_train = np.unique(X_train[:, i])\n",
    "        diffs = np.diff(unique_X_train)\n",
    "        if len(diffs) == 0:\n",
    "            theta_vals = [-np.inf, np.inf]\n",
    "        else:\n",
    "            theta_vals = np.hstack(([-np.inf], unique_X_train[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "\n",
    "        for s in [-1, 1]:\n",
    "            for theta in theta_vals:\n",
    "                predictions = s * np.sign(X_train[:, i] - theta)\n",
    "                error = np.sum(np.not_equal(predictions, y_train))\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                    best_hypothesis = (i, s, theta)\n",
    "                elif error == min_error and i < best_hypothesis[0]:\n",
    "                    best_hypothesis = (i, s, theta)\n",
    "\n",
    "    def h(x):\n",
    "        i, s, theta = best_hypothesis\n",
    "        return s * np.sign(x[:, i] - theta)\n",
    "\n",
    "    Ein_g = np.mean(np.not_equal(h(X_train), y_train))\n",
    "    Eout_g = np.mean(np.not_equal(h(X_test), y_test))\n",
    "\n",
    "    return Ein_g, Eout_g, Eout_g - Ein_g\n",
    "\n",
    "Ein_g1, Eout_g1, Eout_Ein_diff1 = experiment1()\n",
    "print(f\"Ein(g1): {Ein_g1:.5f}\")\n",
    "print(f\"Eout(g1): {Eout_g1:.5f}\")\n",
    "print(f\"Eout(g1) - Ein(g1): {Eout_Ein_diff1:.5f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19、20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein(g2): 0.32812\n",
      "Eout(g2): 0.42188\n",
      "Eout(g2) - Ein(g2): 0.09375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def experiment2():\n",
    "    df_train = pd.read_csv('ML_HW2_data_train.dat', sep=\"\\t\", header=None)\n",
    "    X_train = df_train.iloc[:, :-1].to_numpy()\n",
    "    y_train = df_train.iloc[:, -1].to_numpy()\n",
    "    sample_size_train = df_train.shape[0]\n",
    "    num_features = X_train.shape[1]\n",
    "\n",
    "    df_test = pd.read_csv('ML_HW2_data_test.dat', sep=\"\\t\", header=None)\n",
    "    X_test = df_test.iloc[:, :-1].to_numpy()\n",
    "    y_test = df_test.iloc[:, -1].to_numpy()\n",
    "    sample_size_test = df_test.shape[0]\n",
    "\n",
    "    best_hypotheses = [None] * num_features\n",
    "    min_errors = np.inf * np.ones(num_features)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        unique_X_train = np.unique(X_train[:, i])\n",
    "        diffs = np.diff(unique_X_train)\n",
    "        if len(diffs) == 0:\n",
    "            theta_vals = [-np.inf, np.inf]\n",
    "        else:\n",
    "            theta_vals = np.hstack(([-np.inf], unique_X_train[:-1][diffs != 0] + diffs[diffs != 0] / 2, [np.inf]))\n",
    "\n",
    "        for s in [-1, 1]:\n",
    "            for theta in theta_vals:\n",
    "                predictions = s * np.sign(X_train[:, i] - theta)\n",
    "                error = np.mean(np.not_equal(predictions, y_train))\n",
    "\n",
    "                if error < min_errors[i]:\n",
    "                    min_errors[i] = error\n",
    "                    best_hypotheses[i] = (i, s, theta)\n",
    "                elif error == min_errors[i] and i < best_hypotheses[i][0]:\n",
    "                    best_hypotheses[i] = (i, s, theta)\n",
    "\n",
    "    best_hypothesis = best_hypotheses[np.argmax(min_errors)]\n",
    "\n",
    "    def h(x):\n",
    "        i, s, theta = best_hypothesis\n",
    "        return s * np.sign(x[:, i] - theta)\n",
    "\n",
    "    Ein_g2 = np.mean(np.not_equal(h(X_train), y_train))\n",
    "    Eout_g2 = np.mean(np.not_equal(h(X_test), y_test))\n",
    "\n",
    "    return Ein_g2, Eout_g2, Eout_g2 - Ein_g2\n",
    "\n",
    "Ein_g2, Eout_g2, Eout_Ein_diff2 = experiment2()\n",
    "print(f\"Ein(g2): {Ein_g2:.5f}\")\n",
    "print(f\"Eout(g2): {Eout_g2:.5f}\")\n",
    "print(f\"Eout(g2) - Ein(g2): {Eout_Ein_diff2:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_Ein = 0.30208\n",
      "delta_Eout = 0.34375\n"
     ]
    }
   ],
   "source": [
    "print(f\"delta_Ein = {Ein_g2 - Ein_g1:.5f}\")\n",
    "print(f\"delta_Eout = {Eout_g2 - Eout_g1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
