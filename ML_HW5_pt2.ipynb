{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm.svmutil import *\n",
    "from liblinear.liblinearutil import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "from math import log, exp\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "y_train, X_train = svm_read_problem(\"letter_train\")\n",
    "y_test, X_test = svm_read_problem(\"letter_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the training data\n",
    "X_tr = []\n",
    "y_tr = []\n",
    "\n",
    "for num in range(len(y_train)):\n",
    "    if y_train[num] == 11:\n",
    "        new = 1\n",
    "        y_tr.append(new)\n",
    "        X_tr.append([X_train[num][k] for k in range(1, len(X_train[num]) + 1)])\n",
    "    elif y_train[num] == 26:\n",
    "        new = -1\n",
    "        y_tr.append(new)\n",
    "        X_tr.append([X_train[num][k] for k in range(1, len(X_train[num]) + 1)])\n",
    "\n",
    "# Label the test data\n",
    "X_t = []\n",
    "y_t = []\n",
    "\n",
    "for num in range(len(y_test)):\n",
    "    if y_test[num] == 11:\n",
    "        new = 1\n",
    "        y_t.append(new)\n",
    "        X_t.append([X_test[num][k] for k in range(1, len(X_test[num]) + 1)])\n",
    "    elif y_test[num] == 26:\n",
    "        new = -1\n",
    "        y_t.append(new)\n",
    "        X_t.append([X_test[num][k] for k in range(1, len(X_test[num]) + 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rate(pred, true, weights):\n",
    "    # Calculate the error rate using the weighted 0/1 error\n",
    "    error = sum(w for i, w in enumerate(weights) if pred[i] != true[i])\n",
    "    return error / sum(weights)\n",
    "\n",
    "def decision_stump(X, y, weights):\n",
    "    # Implement the decision stump algorithm\n",
    "    num_samples, num_features = len(X), len(X[0])\n",
    "    best_error = float('inf')\n",
    "    best_feature, best_threshold, best_s = None, None, None\n",
    "\n",
    "    for i in range(num_features):\n",
    "        sorted_indices = sorted(range(num_samples), key=lambda x: X[x][i])\n",
    "        thresholds = [float('-inf')] + [(X[sorted_indices[j]][i] + X[sorted_indices[j+1]][i]) / 2 for j in range(num_samples - 1)]\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            for s in [-1, 1]:\n",
    "                pred = [s if x[i] < threshold else -s for x in X]\n",
    "                error = get_error_rate(pred, y, weights)\n",
    "\n",
    "                if error < best_error:\n",
    "                    best_error = error\n",
    "                    best_feature = i\n",
    "                    best_threshold = threshold\n",
    "                    best_s = s\n",
    "    \n",
    "    return best_feature, best_threshold, best_s, best_error\n",
    "\n",
    "def adaboost_stump(X, y, T):\n",
    "    num_samples = len(X)\n",
    "    num_features = len(X[0])\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = [1 / num_samples] * num_samples\n",
    "\n",
    "    alphas = []\n",
    "    classifiers = []\n",
    "\n",
    "    for t in range(T):\n",
    "        # Train a decision stump\n",
    "        feature, threshold, s, error = decision_stump(X, y, weights)\n",
    "\n",
    "        # Calculate alpha\n",
    "        alpha = 0.5 * log((1 - error) / error)\n",
    "        alphas.append(alpha)\n",
    "\n",
    "        # Update weights\n",
    "        Z = sum(weights)\n",
    "        weights = [w * exp(-alpha * p * t) / Z for w, p, t in zip(weights, [s if x[feature] < threshold else -s for x in X], y)]\n",
    "\n",
    "        # Save the classifier\n",
    "        classifiers.append((feature, threshold, s))\n",
    "        # Print progress\n",
    "        print(\"Iteration\", t + 1, \"completed\")\n",
    "\n",
    "    return alphas, classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stump_predict(x, stump):\n",
    "    feature = stump[0]       # Access feature index using index 0\n",
    "    threshold = stump[1]     # Access threshold using index 1\n",
    "    s = stump[2]             # Access s value using index 2\n",
    "\n",
    "    return s if x[feature] < threshold else -s\n",
    "\n",
    "def evaluate(X, y, alphas, classifiers):\n",
    "    num_samples = len(X)\n",
    "    num_classifiers = len(classifiers)\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        prediction = sum(alpha * stump_predict(X[i], classifier) for alpha, classifier in zip(alphas, classifiers))\n",
    "        errors.append(int(np.sign(prediction) != y[i]))\n",
    "\n",
    "    ein_G = sum(alpha * error for alpha, error in zip(alphas, errors)) / num_samples\n",
    "    eout_G = sum(errors) / num_samples\n",
    "\n",
    "    return ein_G, eout_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AdaBoost-Stump on the training data\n",
    "T = 1000\n",
    "alphas, classifiers = adaboost_stump(X_tr, y_tr, T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_{1≤t≤1000} Ein(gt): 0.09846547314578005\n",
      "max_{1≤t≤1000} Ein(gt): 0.571611253196931\n",
      "Ein(G): 0.00000\n",
      "Eout(G): 0.00279\n"
     ]
    }
   ],
   "source": [
    "# Calculate Ein(G), Eout(G)\n",
    "ein_G, _ = evaluate(X_tr, y_tr, alphas, classifiers)\n",
    "_, eout_G = evaluate(X_t, y_t, alphas, classifiers)\n",
    "\n",
    "# Calculate min_{1≤t≤1000} Ein(gt)\n",
    "min_ein = min(get_error_rate([s if X_tr[i][feature] < threshold else -s for i in range(len(X_tr))], y_tr, [1] * len(X_tr)) for feature, threshold, s in classifiers)\n",
    "# Calculate max_{1≤t≤1000} Ein(gt)\n",
    "max_ein = max(get_error_rate([s if X_tr[i][feature] < threshold else -s for i in range(len(X_tr))], y_tr, [1] * len(X_tr)) for feature, threshold, s in classifiers)\n",
    "\n",
    "# Print the results\n",
    "print(\"min_{1≤t≤1000} Ein(gt):\", min_ein)\n",
    "print(\"max_{1≤t≤1000} Ein(gt):\", max_ein)\n",
    "\n",
    "print(\"Ein(G):\", \"{:.5f}\".format(ein_G))\n",
    "print(\"Eout(G):\", \"{:.5f}\".format(eout_G))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
